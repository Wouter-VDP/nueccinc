{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_formatted_code = \"%load_ext autoreload\\n%matplotlib inline\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%matplotlib inline\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_formatted_code = \"import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nfrom helpers import helpfunction as helper\\nfrom joblib import dump, load\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import classification_report\\nfrom xgboost import XGBClassifier\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.metrics import roc_curve, auc\\nimport pickle\\n\\npd.set_option(\\\"display.max_columns\\\", 500)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import helpfunction as helper\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import pickle\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_formatted_code = \"%autoreload\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_formatted_code = \"x_sce_magic = 1.03\\npid_upper_clip = 300\\npot_target = 1e20\\nlee_focus = 2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_sce_magic = 1.03\n",
    "pid_upper_clip = 300\n",
    "pot_target = 1e20\n",
    "lee_focus = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_formatted_code = \"max_trk_score = 0.15\\nmin_cluster_frac = 0.6\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_trk_score = 0.15\n",
    "min_cluster_frac = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_formatted_code = \"x_sce_magic = 1.03\\npid_upper_clip = 300\\npot_target = 1e20\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_sce_magic = 1.03\n",
    "pid_upper_clip = 300\n",
    "pot_target = 1e20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_formatted_code = \"max_trk_score = 0.15\\nmin_cluster_frac = 0.6\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_trk_score = 0.15\n",
    "min_cluster_frac = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_formatted_code = \"run = 1\\ninput_dir = \\\"./input/13Nov/run{}/\\\".format(run)\\noutput_dir = \\\"./output/run{}/\\\".format(run)\\nmodel_dir = \\\"./models/run{}/\\\".format(run)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = 1\n",
    "input_dir = \"./input/13Nov/run{}/\".format(run)\n",
    "output_dir = \"./output/run{}/\".format(run)\n",
    "model_dir = \"./models/run{}/\".format(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Summary: [name, POT, Scaling, Events, SliceID passing rate]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "not found: b'contained_sps_ratio'\n in file: ./input/13Nov/run1/run1_bnb_dirt_cc0pinp.root",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Binaries/miniconda3/envs/uproot/lib/python3.7/site-packages/uproot/tree.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, name, recursive, filtername, filtertitle, aliases)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_branchlookup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: b'contained_sps_ratio'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-caa290229b3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexclude_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msample_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_sample_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpot_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpot_target\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msample_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"on\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pot\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Jupyter/searchingfornues/helpers/helpfunction.py\u001b[0m in \u001b[0;36mload_sample_info\u001b[0;34m(input_dir, run, exclude_samples)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mcols_load\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0mcols_run3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0msample_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'daughters'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmain_tree\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0msample_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'daughters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trk_min_cos'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_max_angle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmain_tree\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0msample_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'daughters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'event'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'daughter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Binaries/miniconda3/envs/uproot/lib/python3.7/site-packages/uproot/_connect/_pandas.py\u001b[0m in \u001b[0;36mdf\u001b[0;34m(self, branches, namedecode, entrystart, entrystop, flatten, flatname, awkwardlib, cache, basketcache, keycache, executor, blocking)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamedecode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentrystart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentrystop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mawkwardlib\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasketcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeycache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbranches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbranches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamedecode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnamedecode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentrystart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mentrystart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentrystop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mentrystop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflatname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mawkwardlib\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mawkwardlib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasketcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbasketcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeycache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeycache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentrysteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamedecode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentrystart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentrystop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mawkwardlib\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasketcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeycache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Binaries/miniconda3/envs/uproot/lib/python3.7/site-packages/uproot/tree.py\u001b[0m in \u001b[0;36marrays\u001b[0;34m(self, branches, outputtype, namedecode, entrystart, entrystop, flatten, flatname, awkwardlib, cache, basketcache, keycache, executor, blocking)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamedecode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentrystart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentrystop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mawkwardlib\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasketcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeycache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mawkward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_awkwardlib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mawkwardlib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0mbranches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize_branches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbranches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mawkward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbranch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpretation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbranches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbranch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recoveredbaskets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Binaries/miniconda3/envs/uproot/lib/python3.7/site-packages/uproot/tree.py\u001b[0m in \u001b[0;36m_normalize_branches\u001b[0;34m(self, arg, awkward, allownone, allowcallable, allowdict, allowstring, aliases)\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                         \u001b[0mbranch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maliases\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maliases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                         \u001b[0minterpretation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbranch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mawkward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0minterpretation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Binaries/miniconda3/envs/uproot/lib/python3.7/site-packages/uproot/tree.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, name, recursive, filtername, filtertitle, aliases)\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_branchlookup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0muproot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrootio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_KeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"not found: {0}\\n in file: {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msourcepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: not found: b'contained_sps_ratio'\n in file: ./input/13Nov/run1/run1_bnb_dirt_cc0pinp.root"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_formatted_code = \"exclude_samples = []\\nsample_info, fields = helper.load_sample_info(input_dir, run, exclude_samples)\\npot_scale = pot_target / sample_info[\\\"on\\\"][\\\"pot\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exclude_samples = []\n",
    "sample_info, fields = helper.load_sample_info(input_dir, run, exclude_samples)\n",
    "pot_scale = pot_target / sample_info[\"on\"][\"pot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shr_fields = [f for f in fields if f.startswith(\"shr_\") and f.endswith(\"_v\")]\n",
    "trk_fields = [f for f in fields if f.startswith(\"trk_\") and f.endswith(\"_v\")]\n",
    "backracked_fields = [f for f in fields if f.startswith(\"backtracked_\")]\n",
    "mc_fields = [f for f in fields if f.startswith((\"true_\", \"mc_\"))]\n",
    "other_fields = (\n",
    "    set(fields)\n",
    "    - set(shr_fields)\n",
    "    - set(trk_fields)\n",
    "    - set(backracked_fields)\n",
    "    - set(mc_fields)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trk_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shr_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "backracked_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "other_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search through fields:\n",
    "[f for f in fields if \"ll\" in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# For all samples\n",
    "for k, v in sample_info.items():\n",
    "    # Add fiducial reco sce vtx\n",
    "    v[\"daughters\"][\"reco_fid_vol\"] = np.repeat(\n",
    "        helper.is_fid(\n",
    "            *v[\"daughters\"][\n",
    "                [\"reco_nu_vtx_sce_x\", \"reco_nu_vtx_sce_y\", \"reco_nu_vtx_sce_z\"]\n",
    "            ]\n",
    "            .xs(0, level=\"daughter\")\n",
    "            .values.T\n",
    "        ),\n",
    "        v[\"daughters\"][\"n_pfps\"].xs(0, level=\"daughter\"),\n",
    "    )\n",
    "    # Add pfp at vtx:\n",
    "    v[\"daughters\"][\"n_pfpvtx\"] = v[\"daughters\"].eval(\"trk_distance_v<3 & trk_distance_v>=0\")\n",
    "    v[\"daughters\"][\"n_pfpvtx\"] = v[\"daughters\"]['n_pfpvtx'].groupby(\"event\").transform(sum)\n",
    "    v[\"daughters\"][\"n_pfp_farvtx\"] = v[\"daughters\"].eval(\"n_pfps-n_pfpvtx\")\n",
    "    \n",
    "    # Add electron candidate check\n",
    "    e_cand_str = 'pfnplanehits_U>0 & pfnplanehits_V>0 & pfnplanehits_Y>0 & trk_score_v<@max_trk_score & shr_tkfit_dedx_nhits_y_v>0'    \n",
    "    data = v[\"daughters\"][\n",
    "                [\n",
    "                    \"pfnplanehits_U\", \"pfnplanehits_V\", \"pfnplanehits_Y\",\n",
    "                    \"trk_score_v\",'shr_tkfit_dedx_nhits_y_v',\n",
    "                    \"shr_dist_v\",\n",
    "                ]\n",
    "            ]\n",
    "    electron_candidate = data.eval(e_cand_str)\n",
    "    e_cand_maxe = data[electron_candidate][\"shr_dist_v\"].groupby(\"event\").transform(min) == data[electron_candidate][\"shr_dist_v\"]\n",
    "    v[\"daughters\"][\"e_candidate\"] = False\n",
    "    v[\"daughters\"].loc[e_cand_maxe[e_cand_maxe == True].index, \"e_candidate\"] = True\n",
    "    # Add weighted dedx:\n",
    "    dedx_cols = [\"shr_tkfit_dedx_u_v\",\n",
    "                    \"shr_tkfit_dedx_v_v\",\n",
    "                    \"shr_tkfit_dedx_y_v\",\n",
    "                    'shr_tkfit_nhits_v',\n",
    "                    \"shr_tkfit_dedx_nhits_u_v\",\n",
    "                    \"shr_tkfit_dedx_nhits_v_v\",\n",
    "                    \"shr_tkfit_dedx_nhits_y_v\"]\n",
    "    v[\"daughters\"][dedx_cols]=v[\"daughters\"][dedx_cols].clip(lower=0)\n",
    "    str_dedx_weighted_mean='(shr_tkfit_dedx_u_v*shr_tkfit_dedx_nhits_u_v+shr_tkfit_dedx_v_v*shr_tkfit_dedx_nhits_v_v+shr_tkfit_dedx_y_v*shr_tkfit_dedx_nhits_y_v)/(shr_tkfit_dedx_nhits_u_v+shr_tkfit_dedx_nhits_v_v+shr_tkfit_dedx_nhits_y_v)'\n",
    "    v[\"daughters\"]['shr_tkfit_dedx_wm_v']= v[\"daughters\"].eval(str_dedx_weighted_mean)\n",
    "    # Add weigthed pid chi mu/pr:\n",
    "    pid_chi_cols = [\"trk_pid_chipr_v\",\n",
    "    \"trk_pid_chimu_v\",\n",
    "    \"trk_pid_chipr_v_v\",\n",
    "    \"trk_pid_chimu_v_v\",\n",
    "    \"trk_pid_chipr_u_v\",\n",
    "    \"trk_pid_chimu_u_v\"]\n",
    "    v[\"daughters\"][pid_chi_cols]=v[\"daughters\"][pid_chi_cols].clip(upper=pid_upper_clip)\n",
    "    str_pidmu_weighted_mean='(trk_pid_chimu_v*pfnplanehits_Y+trk_pid_chimu_v_v*pfnplanehits_V+trk_pid_chimu_u_v*pfnplanehits_U)/pfnhits'\n",
    "    v[\"daughters\"]['trk_pid_chimu_wm_v']= v[\"daughters\"].eval(str_pidmu_weighted_mean)\n",
    "    str_pidpr_weighted_mean='(trk_pid_chipr_v*pfnplanehits_Y+trk_pid_chipr_v_v*pfnplanehits_V+trk_pid_chipr_u_v*pfnplanehits_U)/pfnhits'\n",
    "    v[\"daughters\"]['trk_pid_chipr_wm_v']= v[\"daughters\"].eval(str_pidpr_weighted_mean)\n",
    "    # Add the number of hits per length:\n",
    "    v[\"daughters\"]['hits_per_tklen']= v[\"daughters\"].eval('pfnhits/trk_len_v')\n",
    "    \n",
    "    # Drop columns I do not need anymore:\n",
    "    drop_cols = [\n",
    "    \"pfnplanehits_U\",\n",
    "    \"pfnplanehits_V\",\n",
    "    \"pfnplanehits_Y\",\n",
    "    'pfnhits',\n",
    "    \"shr_tkfit_dedx_u_v\",\n",
    "    \"shr_tkfit_dedx_v_v\",\n",
    "    \"shr_tkfit_nhits_v\",\n",
    "    \"shr_tkfit_dedx_nhits_u_v\",\n",
    "    \"shr_tkfit_dedx_nhits_v_v\",    \n",
    "    \"trk_pid_chipr_v_v\",\n",
    "    \"trk_pid_chimu_v_v\",\n",
    "    \"trk_pid_chipr_u_v\",\n",
    "    \"trk_pid_chimu_u_v\",\n",
    "]\n",
    "for c in drop_cols:\n",
    "    if c in v[\"daughters\"].columns:\n",
    "        v[\"daughters\"].drop(c, inplace=True, axis=1)\n",
    "    else:\n",
    "        print(c, \" was not in dataframe!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# For MC samples\n",
    "for k, v in sample_info.items():\n",
    "    if k not in helper.data_samples:\n",
    "        \n",
    "        # Correct the LEE weight using the splineweight\n",
    "        v['daughters'][\"leeweight\"]*=v['daughters'][\"weightSpline\"]\n",
    "        \n",
    "        # Add distance between reco_sce and true vertex\n",
    "        data = (\n",
    "            v[\"daughters\"][\n",
    "                [\n",
    "                    \"reco_nu_vtx_sce_x\",\n",
    "                    \"reco_nu_vtx_sce_y\",\n",
    "                    \"reco_nu_vtx_sce_z\",\n",
    "                    \"true_nu_vtx_x\",\n",
    "                    \"true_nu_vtx_y\",\n",
    "                    \"true_nu_vtx_z\",\n",
    "                ]\n",
    "            ]\n",
    "            .xs(0, level=\"daughter\")\n",
    "            .values.T\n",
    "        )\n",
    "        data[0]-=x_sce_magic # Correct x location for the 0.6 sign error\n",
    "        \n",
    "        v[\"daughters\"][\"true_vtx_distance\"] = np.repeat(\n",
    "            np.linalg.norm(data[0:3] - data[3:6], axis=0),\n",
    "            v[\"daughters\"][\"n_pfps\"].xs(0, level=\"daughter\"),\n",
    "        )\n",
    "        # Cross-check vtx distance\n",
    "        data = (\n",
    "            v[\"daughters\"][\n",
    "                [\n",
    "                    \"true_nu_vtx_sce_x\",\n",
    "                    \"true_nu_vtx_sce_y\",\n",
    "                    \"true_nu_vtx_sce_z\",\n",
    "                    \"reco_nu_vtx_x\",\n",
    "                    \"reco_nu_vtx_y\",\n",
    "                    \"reco_nu_vtx_z\",\n",
    "                ]\n",
    "            ]\n",
    "            .xs(0, level=\"daughter\")\n",
    "            .values.T\n",
    "        )\n",
    "        v[\"daughters\"][\"true_vtx_distance_check\"] = np.repeat(\n",
    "            np.linalg.norm(data[0:3] - data[3:6], axis=0),\n",
    "            v[\"daughters\"][\"n_pfps\"].xs(0, level=\"daughter\"),\n",
    "        )\n",
    "        # Add the distance between the true neutrino vertex and the reconstructed shower start point\n",
    "        data = (\n",
    "            v[\"daughters\"][\n",
    "                [\n",
    "                    \"true_nu_vtx_sce_x\",\n",
    "                    \"true_nu_vtx_sce_y\",\n",
    "                    \"true_nu_vtx_sce_z\",\n",
    "                    \"shr_tkfit_start_x_v\",\n",
    "                    \"shr_tkfit_start_y_v\",\n",
    "                    \"shr_tkfit_start_z_v\",\n",
    "                ]\n",
    "            ]\n",
    "            .values.T\n",
    "        )\n",
    "        v[\"daughters\"][\"true_shower_distance\"] = np.linalg.norm(data[0:3] - data[3:6], axis=0)\n",
    "        \n",
    "        # Add the modified purity/completeness to account for overlay.\n",
    "        overlay_mask = v[\"daughters\"].eval('backtracked_overlay_purity>backtracked_purity')\n",
    "        v[\"daughters\"].loc[overlay_mask, 'backtracked_pdg'] = 0\n",
    "        v[\"daughters\"].loc[overlay_mask, 'backtracked_purity'] = v[\"daughters\"].loc[overlay_mask, 'backtracked_overlay_purity']\n",
    "        v[\"daughters\"].loc[overlay_mask, 'backtracked_completeness'] = 0\n",
    "        \n",
    "        # Drop some stuff you do not need anymore\n",
    "        drop_cols = ['backtracked_overlay_purity',\n",
    "                     \"true_nu_vtx_sce_y\",\n",
    "                     \"true_nu_vtx_sce_z\",\n",
    "                     \"reco_nu_vtx_y\",\n",
    "                     \"reco_nu_vtx_z\"]\n",
    "        for c in drop_cols:\n",
    "            if c in v[\"daughters\"].columns:\n",
    "                v[\"daughters\"].drop(c, inplace=True, axis=1)\n",
    "            else:\n",
    "                print(c, \" was not in dataframe!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# For MC samples, fields needed as training labels:\n",
    "for k, v in sample_info.items():\n",
    "    if k not in helper.data_samples:\n",
    "        # Add training labels and weights\n",
    "        e_cand = v[\"daughters\"]['e_candidate']\n",
    "        e_good = v[\"daughters\"].eval('e_candidate & abs(backtracked_pdg)==11 & backtracked_purity>0.75 & backtracked_completeness>0.5')\n",
    "        e_cand_bad = v[\"daughters\"].eval('e_candidate & abs(backtracked_pdg)!=11')\n",
    "        other_bad = v[\"daughters\"].eval('~e_candidate & (abs(backtracked_pdg)==13 | backtracked_pdg==22 | backtracked_pdg==0)')\n",
    "        \n",
    "        v[\"daughters\"]['train_weight'] = v[\"daughters\"].eval('weightSpline+leeweight*@lee_focus') # weight low energy electrons a bit higher\n",
    "        v[\"daughters\"]['train_weight'] = v[\"daughters\"].eval('train_weight*(1+(150<shr_energy_y_v<400)*@lee_focus)') # weight low energy electrons a bit higher\n",
    "        \n",
    "        v[\"daughters\"].loc[e_good, \"train_weight\"] *= 5 # can be tuned\n",
    "        \n",
    "        v[\"daughters\"]['train_label'] = True\n",
    "        v[\"daughters\"].loc[e_cand_bad, \"train_label\"] = False\n",
    "        v[\"daughters\"].loc[other_bad, \"train_label\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case we train on external data:\n",
    "# sample_info[\"Off\"][\"daughters\"][\"nueccinc\"] = False\n",
    "# sample_info[\"Off\"][\"daughters\"][\"train_weight\"] = 1\n",
    "# low_e_shr = sample_info[\"Off\"][\"daughters\"].eval(\"shr_energy_y_v<0.4\")\n",
    "# sample_info[\"Off\"][\"daughters\"].loc[low_e_shr, \"train_weight\"] *= 5  # can be tuned\n",
    "# sample_info[\"Off\"][\"daughters\"][\"train_label\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality cuts / Pre-selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_preselect = (\n",
    "    \"e_candidate & reco_fid_vol & slclustfrac>@min_cluster_frac & ~crtveto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Passing rate pre-selection\n",
    "for k, v in sample_info.items():\n",
    "    v[\"daughters\"][\"preselect\"] = v[\"daughters\"].eval(\n",
    "        query_preselect\n",
    "    )\n",
    "    v[\"daughters\"][\"preselect\"] = v[\"daughters\"][\"preselect\"].groupby(\"event\").transform(max)\n",
    "    \n",
    "    pass_rate = sum(v[\"daughters\"].eval(\"e_candidate & preselect\"))/v['numentries']\n",
    "    print(k, \"\\t{:.2f}%\".format(pass_rate * 100))\n",
    "    \n",
    "# Passing rate signal, weights applied!\n",
    "pass_rate = sum(sample_info[\"nue\"]['daughters'].eval('(e_candidate & preselect)*weightSpline*nueccinc'))/sum(sample_info[\"nue\"][\"mc\"]['weightSpline']*sample_info['nue']['mc']['nueccinc'] )\n",
    "print(\"Nue signal passing the preselection \\t{:.2f}%\".format(pass_rate * 100))\n",
    "nue_pass = sum(sample_info[\"nue\"]['daughters'].eval('(e_candidate & preselect)*nueccinc'))*sample_info[\"nue\"]['scaling']*pot_scale\n",
    "print(\"Nue Intrinsic signal passing: {0:0.3f} per {1:0.2g} POT\".format(nue_pass,pot_target))\n",
    "lee_pass = sum(sample_info[\"nue\"]['daughters'].eval('(e_candidate & preselect)*leeweight*nueccinc'))*sample_info[\"nue\"]['scaling']*pot_scale\n",
    "print(\"Nue LEE signal passing: {0:0.3f} per {1:0.2g} POT\".format(lee_pass,pot_target))\n",
    "\n",
    "## Calculate the purity:\n",
    "purity_denom = (\n",
    "    sum(sample_info[\"nu\"][\"daughters\"].eval(\"(e_candidate & preselect)*weightSpline\"))\n",
    "    * sample_info[\"nu\"][\"scaling\"]\n",
    ")\n",
    "purity_denom += (\n",
    "    sum(sample_info[\"dirt\"][\"daughters\"].eval(\"(e_candidate & preselect)*weightSpline\"))\n",
    "    * sample_info[\"dirt\"][\"scaling\"]\n",
    ")\n",
    "purity_denom += (\n",
    "    sum(sample_info[\"off\"][\"daughters\"].eval(\"(e_candidate & preselect)\")) * sample_info[\"off\"][\"scaling\"]\n",
    ")\n",
    "\n",
    "purity_mc = (\n",
    "    sum(sample_info[\"nue\"][\"daughters\"].eval(\"(e_candidate & preselect)*weightSpline*nueccinc\"))\n",
    "    * sample_info[\"nue\"][\"scaling\"]\n",
    "    / purity_denom\n",
    ")\n",
    "purity_data = (\n",
    "    sum(sample_info[\"nue\"][\"daughters\"].eval(\"(e_candidate & preselect)*weightSpline*nueccinc\"))\n",
    "    * sample_info[\"nue\"][\"scaling\"]\n",
    "    / sum(sample_info[\"on\"][\"daughters\"].eval(\"(e_candidate & preselect)\"))\n",
    ")\n",
    "print(\n",
    "    \"Purity MC: {:.1f}%\\nData/MC-ratio: {:.2f}\\n\".format(\n",
    "        purity_mc * 100,\n",
    "        sum(sample_info[\"on\"][\"daughters\"].eval(\"(e_candidate & preselect)\")) / purity_denom,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_train_electron = [\n",
    "    # \"topological_score\",\n",
    "    # \"n_pfpvtx\",\n",
    "    \"n_showers\",\n",
    "    # \"n_tracks\",\n",
    "    # \"trk_score_v\",\n",
    "    # \"trk_len_v\",\n",
    "    #\"trk_pid_chipr_v\",\n",
    "    #\"trk_pid_chimu_v\",\n",
    "    \"trk_llr_pid_score_v\",\n",
    "    \"trk_min_cos\",\n",
    "    \"hits_per_tklen\",\n",
    "    \"shr_dist_v\",\n",
    "    \"shr_energy_y_v\",\n",
    "    # \"shr_openangle_v\",\n",
    "    # \"shr_tkfit_theta_v\",\n",
    "    # \"shr_tkfit_phi_v\",\n",
    "    \"shr_tkfit_dedx_wm_v\",\n",
    "    \"shr_tkfit_dedx_y_v\",\n",
    "    \"shr_tkfit_gap10_dedx_y_v\",\n",
    "    'shr_moliere_avg_v',\n",
    "    'shr_moliere_rms_v'\n",
    "    # \"shr_tkfit_dedx_nhits_y_v\",\n",
    "    ##\"train_weight\",\n",
    "    ##\"train_label\",\n",
    "]\n",
    "col_train_other = [\n",
    "    # \"topological_score\",\n",
    "    # \"n_showers\",\n",
    "    # \"n_tracks\",\n",
    "    # \"n_pfpvtx\",\n",
    "    \"trk_score_v\",\n",
    "    \"trk_distance_v\",\n",
    "    \"trk_theta_v\",\n",
    "    # \"trk_phi_v\",\n",
    "    \"trk_len_v\",\n",
    "    \"trk_llr_pid_score_v\"\n",
    "    #\"trk_pid_chimu_wm_v\",\n",
    "    #\"trk_pid_chipr_wm_v\",\n",
    "    # \"trk_min_cos\",\n",
    "    # \"hits_per_tklen\",\n",
    "    \"shr_energy_y_v\",\n",
    "    # \"shr_openangle_v\",\n",
    "    \"shr_tkfit_dedx_wm_v\",\n",
    "    ##\"train_weight\",\n",
    "    ##\"train_label\",\n",
    "]\n",
    "\n",
    "col_train_event = [\n",
    "    \"topological_score\",\n",
    "    # \"n_showers\",\n",
    "    # \"n_tracks\",\n",
    "    # \"n_pfpvtx\",\n",
    "    \"n_pfp_farvtx\",\n",
    "    \"hits_ratio\",\n",
    "    \"contained_fraction\",\n",
    "    \"score\",\n",
    "    # \"score_other_max\",\n",
    "    \"score_other_min\",\n",
    "    \"score_other_mean\",\n",
    "    \"CosmicIP\"\n",
    "    # \"nu_flashmatch_score\",\n",
    "    ## nueccinc\n",
    "    ## train_weight -> use the train weight of the electron candidate\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Electron training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q = \"preselect & e_candidate\"\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for k in train_samples:\n",
    "    X = sample_info[k][\"daughters\"].query(train_q)[col_train_electron]\n",
    "    Y = sample_info[k][\"daughters\"].query(train_q)[[\"train_label\", \"train_weight\"]]\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X, Y, test_size=test_size, random_state=seed\n",
    "    )\n",
    "    X_train.append(X_tr)\n",
    "    X_test.append(X_te)\n",
    "    y_train.append(y_tr)\n",
    "    y_test.append(y_te)\n",
    "\n",
    "# Merge our two samples\n",
    "X_train = pd.concat(X_train).reset_index(drop=True)\n",
    "y_train = pd.concat(y_train).reset_index(drop=True)\n",
    "X_test = pd.concat(X_test).reset_index(drop=True)\n",
    "y_test = pd.concat(y_test).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model no training data\n",
    "if retrain:\n",
    "    model_e = XGBClassifier(max_depth=5)\n",
    "    model_e.fit(X_train, y_train[\"train_label\"], sample_weight=y_train[\"train_weight\"])\n",
    "    dump(model_e, model_dir + \"model_e.pckl\")\n",
    "else:\n",
    "    model_e = load(model_dir + \"model_e.pckl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model_e.predict(X_test)\n",
    "target_names = [\"electron\", \"non_electron\"]\n",
    "print(classification_report(y_test[\"train_label\"], y_pred, target_names=target_names))\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test[\"train_label\"], predictions)\n",
    "print(\"Test accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred_train = model_e.predict(X_train)\n",
    "predictions = [round(value) for value in y_pred_train]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_train[\"train_label\"], predictions)\n",
    "print(\"Train accuracy: %.2f%%\\n\" % (accuracy * 100.0))\n",
    "\n",
    "importances = model_e.feature_importances_\n",
    "sort = np.argsort(-importances)\n",
    "\n",
    "for i, (n, im) in enumerate(zip(np.array(col_train_electron)[sort], importances[sort])):\n",
    "    print(\"%d. feature %s (%f)\" % (i + 1, n, im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(8, 4))\n",
    "\n",
    "y_pred = model_e.predict_proba(X_test).T[1]\n",
    "fpr, tpr, _ = roc_curve(y_test[\"train_label\"], y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "ax[0].hist(\n",
    "    y_pred[y_test[\"train_label\"] == 0],\n",
    "    alpha=0.5,\n",
    "    bins=50,\n",
    "    range=(0, 1),\n",
    "    label=\"no electrons\",\n",
    "    density=False,\n",
    ")\n",
    "ax[0].hist(\n",
    "    y_pred[(y_test[\"train_label\"] == 1) & (y_test[\"train_weight\"] > 2)],\n",
    "    alpha=0.5,\n",
    "    bins=50,\n",
    "    range=(0, 1),\n",
    "    label=\"good electrons\",\n",
    "    density=False,\n",
    ")\n",
    "ax[0].hist(\n",
    "    y_pred[(y_test[\"train_label\"] == 1) & (y_test[\"train_weight\"] < 2)],\n",
    "    alpha=0.5,\n",
    "    bins=50,\n",
    "    range=(0, 1),\n",
    "    label=\"bad electrons\",\n",
    "    density=False,\n",
    ")\n",
    "ax[0].legend(loc=\"upper left\")\n",
    "ax[0].set_xlim(0, 1)\n",
    "ax[0].set_xlabel(\"Electron identification\")\n",
    "ax[0].set_ylabel(\"Entries per bin\")\n",
    "ax[0].set_title(\"Electron Candidate XGB\")\n",
    "\n",
    "ax[1].plot(fpr, tpr, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(output_dir + \"e_bdt_test.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other daughters training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q = \"preselect & ~e_candidate\"\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for k in train_samples:\n",
    "    X = sample_info[k][\"daughters\"].query(train_q)[col_train_other]\n",
    "    Y = sample_info[k][\"daughters\"].query(train_q)[[\"train_label\", \"train_weight\"]]\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X, Y, test_size=test_size, random_state=seed\n",
    "    )\n",
    "    X_train.append(X_tr)\n",
    "    X_test.append(X_te)\n",
    "    y_train.append(y_tr)\n",
    "    y_test.append(y_te)\n",
    "\n",
    "# Merge our two samples\n",
    "X_train = pd.concat(X_train).reset_index(drop=True)\n",
    "y_train = pd.concat(y_train).reset_index(drop=True)\n",
    "X_test = pd.concat(X_test).reset_index(drop=True)\n",
    "y_test = pd.concat(y_test).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model on training data\n",
    "if retrain:\n",
    "    model_d = XGBClassifier(max_depth=5)\n",
    "    model_d.fit(X_train, y_train[\"train_label\"], sample_weight=y_train[\"train_weight\"])\n",
    "    dump(model_d, model_dir + \"model_d.pckl\")\n",
    "else:\n",
    "    model_d = load(model_dir + \"model_d.pckl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model_d.predict(X_test)\n",
    "target_names = [\"proton, pion, ...\", \"muon, overlay, photon\"]\n",
    "print(classification_report(y_test[\"train_label\"], y_pred, target_names=target_names))\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test[\"train_label\"], predictions)\n",
    "print(\"Test accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred_train = model_d.predict(X_train)\n",
    "predictions = [round(value) for value in y_pred_train]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_train[\"train_label\"], predictions)\n",
    "print(\"Train accuracy: %.2f%%\\n\" % (accuracy * 100.0))\n",
    "\n",
    "importances = model_d.feature_importances_\n",
    "sort = np.argsort(-importances)\n",
    "\n",
    "for i, (n, im) in enumerate(zip(np.array(col_train_other)[sort], importances[sort])):\n",
    "    print(\"%d. feature %s (%f)\" % (i + 1, n, im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(8, 4))\n",
    "\n",
    "y_pred = model_d.predict_proba(X_test).T[1]\n",
    "fpr, tpr, _ = roc_curve(y_test[\"train_label\"], y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "ax[0].hist(\n",
    "    y_pred[y_test[\"train_label\"] == 0],\n",
    "    alpha=0.5,\n",
    "    bins=50,\n",
    "    range=(0, 1),\n",
    "    label=\"muon, overlay, photon\",\n",
    "    density=False,\n",
    ")\n",
    "ax[0].hist(\n",
    "    y_pred[y_test[\"train_label\"] == 1],\n",
    "    alpha=0.5,\n",
    "    bins=50,\n",
    "    range=(0, 1),\n",
    "    label=\"proton, pion, ...\",\n",
    "    density=False,\n",
    ")\n",
    "ax[0].legend(loc=\"upper left\")\n",
    "ax[0].set_xlim(0, 1)\n",
    "ax[0].set_xlabel(\"Daughter identification\")\n",
    "ax[0].set_ylabel(\"Entries per bin\")\n",
    "ax[0].set_title(\"Daughter XGB\")\n",
    "\n",
    "ax[1].plot(fpr, tpr, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(output_dir + \"daughter_bdt_test.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply models on the samples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# add the columns for each daughter (all samples)\n",
    "for k, v in sample_info.items():\n",
    "    v[\"daughters\"][\"score\"] = -1\n",
    "    mask_e_cand = v[\"daughters\"].eval(\"preselect & e_candidate\")\n",
    "    v[\"daughters\"].loc[mask_e_cand, \"score\"] = model_e.predict_proba(\n",
    "        v[\"daughters\"][col_train_electron][mask_e_cand]\n",
    "    ).T[1]\n",
    "    mask_d = v[\"daughters\"].eval(\"preselect & ~e_candidate\")\n",
    "    v[\"daughters\"].loc[mask_d, \"score\"] = model_d.predict_proba(\n",
    "        v[\"daughters\"][col_train_other][mask_d]\n",
    "    ).T[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# First we need to add some columns:\n",
    "for k, v in sample_info.items():    \n",
    "    mask_e = v[\"daughters\"].eval(\"preselect & e_candidate & n_pfps>1\")\n",
    "    v[\"daughters\"][\"score_other_max\"] = 1\n",
    "    v[\"daughters\"].loc[mask_e, \"score_other_max\"] = (\n",
    "        v[\"daughters\"]\n",
    "        .query(\"~e_candidate & preselect\")[\"score\"]\n",
    "        .groupby(\"event\")\n",
    "        .max()\n",
    "        .values\n",
    "    )\n",
    "    v[\"daughters\"][\"score_other_mean\"] = 0.95\n",
    "    v[\"daughters\"].loc[mask_e, \"score_other_mean\"] = (\n",
    "        v[\"daughters\"]\n",
    "        .query(\"~e_candidate & preselect\")[\"score\"]\n",
    "        .groupby(\"event\")\n",
    "        .mean()\n",
    "        .values\n",
    "    )\n",
    "    v[\"daughters\"][\"score_other_min\"] = 0.9\n",
    "    v[\"daughters\"].loc[mask_e, \"score_other_min\"] = (\n",
    "        v[\"daughters\"]\n",
    "        .query(\"~e_candidate & preselect\")[\"score\"]\n",
    "        .groupby(\"event\")\n",
    "        .min()\n",
    "        .values\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q = \"preselect & e_candidate\"\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for k in train_samples:\n",
    "    X = sample_info[k][\"daughters\"].query(train_q)[col_train_event]\n",
    "    Y = sample_info[k][\"daughters\"].query(train_q)[[\"nueccinc\", \"train_weight\"]]\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X, Y, test_size=test_size, random_state=seed\n",
    "    )\n",
    "    X_train.append(X_tr)\n",
    "    X_test.append(X_te)\n",
    "    y_train.append(y_tr)\n",
    "    y_test.append(y_te)\n",
    "\n",
    "# Merge our two samples\n",
    "X_train = pd.concat(X_train).reset_index(drop=True)\n",
    "y_train = pd.concat(y_train).reset_index(drop=True)\n",
    "X_test = pd.concat(X_test).reset_index(drop=True)\n",
    "y_test = pd.concat(y_test).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model on training data\\\n",
    "if retrain:\n",
    "    model_event = XGBClassifier(max_depth=4, n_estimators=200)\n",
    "    model_event.fit(X_train, y_train[\"nueccinc\"], sample_weight=y_train[\"train_weight\"])\n",
    "    dump(model_event, model_dir + \"model_event.pckl\")\n",
    "else:\n",
    "    model_event = load(model_dir + \"model_event.pckl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model_event.predict(X_test)\n",
    "target_names = [\"nueccinc\", \"background events\"]\n",
    "print(classification_report(y_test[\"nueccinc\"], y_pred, target_names=target_names))\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test[\"nueccinc\"], predictions)\n",
    "print(\"Test accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred_train = model_event.predict(X_train)\n",
    "predictions = [round(value) for value in y_pred_train]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_train[\"nueccinc\"], predictions)\n",
    "print(\"Train accuracy: %.2f%%\\n\" % (accuracy * 100.0))\n",
    "\n",
    "importances = model_event.feature_importances_\n",
    "sort = np.argsort(-importances)\n",
    "\n",
    "for i, (n, im) in enumerate(zip(np.array(col_train_event)[sort], importances[sort])):\n",
    "    print(\"%d. feature %s (%f)\" % (i + 1, n, im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(8, 4))\n",
    "\n",
    "y_pred = model_event.predict_proba(X_test).T[1]\n",
    "fpr, tpr, _ = roc_curve(y_test[\"nueccinc\"], y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "ax[0].hist(\n",
    "    y_pred[y_test[\"nueccinc\"] == 0],\n",
    "    alpha=0.5,\n",
    "    bins=50,\n",
    "    range=(0, 1),\n",
    "    label=r\"$\\nu_e$ CC Inclusive\",\n",
    "    density=False,\n",
    ")\n",
    "ax[0].hist(\n",
    "    y_pred[y_test[\"nueccinc\"] == 1],\n",
    "    alpha=0.5,\n",
    "    bins=50,\n",
    "    range=(0, 1),\n",
    "    label=\"background events\",\n",
    "    density=False,\n",
    ")\n",
    "ax[0].legend(loc=\"upper left\")\n",
    "ax[0].set_xlim(0, 1)\n",
    "ax[0].set_xlabel(\"Event identification\")\n",
    "ax[0].set_ylabel(\"Entries per bin\")\n",
    "ax[0].set_title(\"Event XGB\")\n",
    "\n",
    "ax[1].plot(fpr, tpr, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(output_dir + \"event_bdt_test.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# add the columns for each daughter (all samples)\n",
    "for k, v in sample_info.items():\n",
    "    v[\"daughters\"][\"score_event\"] = -1\n",
    "    mask_e_cand = v[\"daughters\"].eval(\"preselect & e_candidate\")\n",
    "    v[\"daughters\"].loc[mask_e_cand, \"score_event\"] = model_event.predict_proba(\n",
    "        v[\"daughters\"][col_train_event][mask_e_cand]\n",
    "    ).T[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_select = \"e_candidate & preselect & score_event>0.9898\"\n",
    "# Passing rate selection\n",
    "for k, v in sample_info.items():\n",
    "\n",
    "    v[\"daughters\"][\"select\"] = v[\"daughters\"].eval(query_select)\n",
    "    v[\"daughters\"][\"select\"] = v[\"daughters\"][\"select\"].groupby(\"event\").transform(max)\n",
    "\n",
    "    pass_rate = sum(v[\"daughters\"].eval(\"(e_candidate & select)\")) / v[\"numentries\"]\n",
    "    print(k, \"\\t{:.4f}%\".format(pass_rate * 100))\n",
    "\n",
    "# Passing rate signal, weights applied!\n",
    "pass_rate = sum(\n",
    "    sample_info[\"NUE\"][\"daughters\"].eval(\"(e_candidate & select)*weightSpline*nueccinc\")\n",
    ") / sum(sample_info[\"NUE\"][\"mc\"][\"weightSpline\"] * sample_info[\"NUE\"][\"nueccinc\"])\n",
    "print(\"Nue signal passing the selection \\t{:.2f}%\".format(pass_rate * 100))\n",
    "nue_pass = (\n",
    "    sum(\n",
    "        sample_info[\"NUE\"][\"daughters\"].eval(\n",
    "            \"(e_candidate & select)*weightSpline*nueccinc\"\n",
    "        )\n",
    "    )\n",
    "    * sample_info[\"NUE\"][\"scaling\"]\n",
    "    * pot_scale\n",
    ")\n",
    "print(\n",
    "    \"Nue Intrinsic signal passing: {0:0.3f} per {1:0.2g} POT\".format(\n",
    "        nue_pass, pot_target\n",
    "    )\n",
    ")\n",
    "lee_pass = (\n",
    "    sum(\n",
    "        sample_info[\"NUE\"][\"daughters\"].eval(\n",
    "            \"(e_candidate & select)*leeweight*nueccinc\"\n",
    "        )\n",
    "    )\n",
    "    * sample_info[\"NUE\"][\"scaling\"]\n",
    "    * pot_scale\n",
    ")\n",
    "print(\"Nue LEE signal passing: {0:0.3f} per {1:0.2g} POT\".format(lee_pass, pot_target))\n",
    "\n",
    "## Calculate the purity:\n",
    "purity_denom = (\n",
    "    sum(sample_info[\"MC\"][\"daughters\"].eval(\"(e_candidate & select)*weightSpline\"))\n",
    "    * sample_info[\"MC\"][\"scaling\"]\n",
    ")\n",
    "purity_denom += (\n",
    "    sum(sample_info[\"DRT\"][\"daughters\"].eval(\"(e_candidate & select)*weightSpline\"))\n",
    "    * sample_info[\"DRT\"][\"scaling\"]\n",
    ")\n",
    "purity_denom += (\n",
    "    sum(sample_info[\"Off\"][\"daughters\"].eval(\"(e_candidate & select)\"))\n",
    "    * sample_info[\"Off\"][\"scaling\"]\n",
    ")\n",
    "\n",
    "purity_mc = (\n",
    "    sum(\n",
    "        sample_info[\"NUE\"][\"daughters\"].eval(\n",
    "            \"(e_candidate & select)*weightSpline*nueccinc\"\n",
    "        )\n",
    "    )\n",
    "    * sample_info[\"NUE\"][\"scaling\"]\n",
    "    / purity_denom\n",
    ")\n",
    "purity_data = (\n",
    "    sum(\n",
    "        sample_info[\"NUE\"][\"daughters\"].eval(\n",
    "            \"(e_candidate & select)*weightSpline*nueccinc\"\n",
    "        )\n",
    "    )\n",
    "    * sample_info[\"NUE\"][\"scaling\"]\n",
    "    / sum(sample_info[\"On\"][\"daughters\"].eval(\"(e_candidate & select)\"))\n",
    ")\n",
    "print(\n",
    "    \"Purity MC: {:.1f}%\\nData/MC-ratio: {:.2f}\\n\".format(\n",
    "        purity_mc * 100,\n",
    "        sum(sample_info[\"On\"][\"daughters\"].eval(\"(e_candidate & select)\"))\n",
    "        / purity_denom,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\n",
    "    output_dir + \"events_run{}.txt\".format(run),\n",
    "    sample_info[\"On\"][\"daughters\"].query(\"(e_candidate & select)\")[\n",
    "        [\"run\", \"sub\", \"evt\"]\n",
    "    ],\n",
    "    fmt=\"%u\",\n",
    ")\n",
    "sample_info[\"On\"][\"daughters\"].query(\"(e_candidate & select)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pickle.dump(sample_info, open(input_dir+\"samples.pckl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(8, 4))\n",
    "\n",
    "ax[0].hist(\n",
    "    sample_info[\"NUE\"][\"daughters\"]\n",
    "    .query(\"nueccinc\")[\"true_vtx_distance\"]\n",
    "    .xs(0, level=\"daughter\"),\n",
    "    bins=50,\n",
    "    range=(0, 5),\n",
    "    label=\"|true_nu_vtx - reco_nu_vtx_sce|\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "ax[0].hist(\n",
    "    sample_info[\"NUE\"][\"daughters\"]\n",
    "    .query(\"nueccinc\")[\"true_vtx_distance_check\"]\n",
    "    .xs(0, level=\"daughter\"),\n",
    "    bins=50,\n",
    "    range=(0, 5),\n",
    "    label=\"|true_nu_vtx_sce - reco_nu_vtx|\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "ax[0].set_xlabel(\"Neutrino vertex distance [cm]\")\n",
    "ax[0].set_title(r\"$\\nu_e$ CC Inclusive\", loc=\"left\")\n",
    "ax[0].set_title(\"Run3 Overlay\", loc=\"right\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].hist(\n",
    "    sample_info[\"NUE\"][\"daughters\"]\n",
    "    .query(\"nueccinc\")\n",
    "    .xs(0, level=\"daughter\")\n",
    "    .eval(\"true_nu_vtx_x+@x_sce_magic-reco_nu_vtx_sce_x\"),\n",
    "    bins=51,\n",
    "    range=(-2, 2),\n",
    "    label=\"|true_nu_vtx - reco_nu_vtx_sce|\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "ax[1].hist(\n",
    "    sample_info[\"NUE\"][\"daughters\"]\n",
    "    .query(\"nueccinc\")\n",
    "    .xs(0, level=\"daughter\")\n",
    "    .eval(\"true_nu_vtx_sce_x-reco_nu_vtx_x\"),\n",
    "    bins=51,\n",
    "    range=(-2, 2),\n",
    "    label=\"|true_nu_vtx_sce - reco_nu_vtx|\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "ax[1].set_xlabel(\"Neutrino vertex distance x-coordinate [cm]\")\n",
    "ax[1].set_title(r\"$\\nu_e$ CC Inclusive\", loc=\"left\")\n",
    "ax[1].set_title(\"Run3 Overlay\", loc=\"right\")\n",
    "ax[1].set_ylim(0, ax[1].get_ylim()[1] * 1.25)\n",
    "ax[1].legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(output_dir + \"vtx_distance.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, figsize=(9, 4))\n",
    "\n",
    "data = sample_info[\"NUE\"][\"daughters\"].query(\"e_candidate & abs(backtracked_pdg==11)\")[\n",
    "    [\"shr_tkfit_dedx_y_v\", \"shr_tkfit_dedx_wm_v\"]\n",
    "]\n",
    "\n",
    "for col in data.columns:\n",
    "    ax.hist(data[col], bins=50, range=(0, 20), label=col, alpha=0.5)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(output_dir + \"e_preselection_dedx.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uproot env",
   "language": "python",
   "name": "uproot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
