{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_formatted_code = \"%load_ext autoreload\\n%matplotlib inline\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%matplotlib inline\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_formatted_code = \"import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nfrom helpers import helpfunction as helper\\nfrom joblib import dump, load\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import classification_report\\nfrom xgboost import XGBClassifier\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.metrics import roc_curve, auc\\nimport pickle\\n\\npd.set_option(\\\"display.max_columns\\\", 500)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import helpfunction as helper\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import pickle\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_formatted_code = \"%autoreload\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_formatted_code = \"x_sce_magic = 1.03\\npid_upper_clip = 300\\npot_target = 1e20\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_sce_magic = 1.03\n",
    "pid_upper_clip = 300\n",
    "pot_target = 1e20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_formatted_code = \"max_trk_score = 0.15\\nmin_cluster_frac = 0.6\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_trk_score = 0.15\n",
    "min_cluster_frac = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_formatted_code = \"x_sce_magic = 1.03\\npid_upper_clip = 300\\npot_target = 1e20\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_sce_magic = 1.03\n",
    "pid_upper_clip = 300\n",
    "pot_target = 1e20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_formatted_code = \"max_trk_score = 0.15\\nmin_cluster_frac = 0.6\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_trk_score = 0.15\n",
    "min_cluster_frac = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_formatted_code = \"run = 1\\ninput_dir = \\\"./input/13Nov/run{}/\\\".format(run)\\noutput_dir = \\\"./output/run{}/\\\".format(run)\\nmodel_dir = \\\"./models/run{}/\\\".format(run)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = 1\n",
    "input_dir = \"./input/13Nov/run{}/\".format(run)\n",
    "output_dir = \"./output/run{}/\".format(run)\n",
    "model_dir = \"./models/run{}/\".format(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Summary: [name, POT, Scaling, Events, SliceID passing rate]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wouter/Binaries/miniconda3/envs/uproot/lib/python3.7/site-packages/awkward/array/jagged.py:1031: RuntimeWarning: overflow encountered in multiply\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/wouter/Binaries/miniconda3/envs/uproot/lib/python3.7/site-packages/awkward/array/jagged.py:1031: RuntimeWarning: overflow encountered in add\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/wouter/Binaries/miniconda3/envs/uproot/lib/python3.7/site-packages/awkward/array/jagged.py:1031: RuntimeWarning: overflow encountered in power\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/wouter/Binaries/miniconda3/envs/uproot/lib/python3.7/site-packages/awkward/array/jagged.py:1031: RuntimeWarning: invalid value encountered in true_divide\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dirt \t2.69e+20 POT\tScaling: 0.14\t85626 events\t NeutrinoID: 22.8%\n",
      "nu \t5.37e+20 POT\tScaling: 0.068\t423777 events\t NeutrinoID: 42.9%\n",
      "nu sample: nueccinc passing Slice ID \t85.14%\n",
      "off \t0 POT\tScaling: 0.26\t377927 events\t NeutrinoID: 14.5%\n",
      "nue \t5.22e+22 POT\tScaling: 0.0007\t87875 events\t NeutrinoID: 79.3%\n",
      "nue sample: nueccinc passing Slice ID \t83.83%\n",
      "on \t3.66e+19 POT\tScaling: 1\t141550 events\t NeutrinoID: 22.9%\n",
      "Completed, time passed: 66.4s.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_formatted_code = \"exclude_samples = []\\nsample_info, fields = helper.load_sample_info(input_dir, run, exclude_samples)\\npot_scale = pot_target / sample_info[\\\"on\\\"][\\\"pot\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exclude_samples = []\n",
    "sample_info, fields = helper.load_sample_info(input_dir, run, exclude_samples)\n",
    "pot_scale = pot_target / sample_info[\"on\"][\"pot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_formatted_code = \"shr_fields = [f for f in fields if f.startswith(\\\"shr_\\\") and f.endswith(\\\"_v\\\")]\\ntrk_fields = [f for f in fields if f.startswith(\\\"trk_\\\") and f.endswith(\\\"_v\\\")]\\nbackracked_fields = [f for f in fields if f.startswith(\\\"backtracked_\\\")]\\nmc_fields = [f for f in fields if f.startswith((\\\"true_\\\", \\\"mc_\\\"))]\\nother_fields = (\\n    set(fields)\\n    - set(shr_fields)\\n    - set(trk_fields)\\n    - set(backracked_fields)\\n    - set(mc_fields)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shr_fields = [f for f in fields if f.startswith(\"shr_\") and f.endswith(\"_v\")]\n",
    "trk_fields = [f for f in fields if f.startswith(\"trk_\") and f.endswith(\"_v\")]\n",
    "backracked_fields = [f for f in fields if f.startswith(\"backtracked_\")]\n",
    "mc_fields = [f for f in fields if f.startswith((\"true_\", \"mc_\"))]\n",
    "other_fields = (\n",
    "    set(fields)\n",
    "    - set(shr_fields)\n",
    "    - set(trk_fields)\n",
    "    - set(backracked_fields)\n",
    "    - set(mc_fields)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trk_score_v',\n",
       " 'trk_bragg_p_v',\n",
       " 'trk_bragg_mu_v',\n",
       " 'trk_bragg_mip_v',\n",
       " 'trk_pida_v',\n",
       " 'trk_pid_chipr_v',\n",
       " 'trk_pid_chipi_v',\n",
       " 'trk_pid_chika_v',\n",
       " 'trk_pid_chimu_v',\n",
       " 'trk_bragg_p_u_v',\n",
       " 'trk_bragg_mu_u_v',\n",
       " 'trk_bragg_mip_u_v',\n",
       " 'trk_pida_u_v',\n",
       " 'trk_pid_chipr_u_v',\n",
       " 'trk_pid_chipi_u_v',\n",
       " 'trk_pid_chika_u_v',\n",
       " 'trk_pid_chimu_u_v',\n",
       " 'trk_bragg_p_v_v',\n",
       " 'trk_bragg_mu_v_v',\n",
       " 'trk_bragg_mip_v_v',\n",
       " 'trk_pida_v_v',\n",
       " 'trk_pid_chipr_v_v',\n",
       " 'trk_pid_chipi_v_v',\n",
       " 'trk_pid_chika_v_v',\n",
       " 'trk_pid_chimu_v_v',\n",
       " 'trk_pfp_id_v',\n",
       " 'trk_dir_x_v',\n",
       " 'trk_dir_y_v',\n",
       " 'trk_dir_z_v',\n",
       " 'trk_start_x_v',\n",
       " 'trk_start_y_v',\n",
       " 'trk_start_z_v',\n",
       " 'trk_sce_start_x_v',\n",
       " 'trk_sce_start_y_v',\n",
       " 'trk_sce_start_z_v',\n",
       " 'trk_end_x_v',\n",
       " 'trk_end_y_v',\n",
       " 'trk_end_z_v',\n",
       " 'trk_sce_end_x_v',\n",
       " 'trk_sce_end_y_v',\n",
       " 'trk_sce_end_z_v',\n",
       " 'trk_distance_v',\n",
       " 'trk_theta_v',\n",
       " 'trk_phi_v',\n",
       " 'trk_len_v',\n",
       " 'trk_mcs_muon_mom_v',\n",
       " 'trk_energy_proton_v',\n",
       " 'trk_energy_muon_v',\n",
       " 'trk_calo_energy_u_v',\n",
       " 'trk_calo_energy_v_v',\n",
       " 'trk_calo_energy_y_v',\n",
       " 'trk_llr_pid_u_v',\n",
       " 'trk_llr_pid_v_v',\n",
       " 'trk_llr_pid_y_v',\n",
       " 'trk_llr_pid_v',\n",
       " 'trk_llr_pid_score_v']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_formatted_code = \"trk_fields\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trk_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shr_dedx_u_v',\n",
       " 'shr_dedx_v_v',\n",
       " 'shr_dedx_y_v',\n",
       " 'shr_energy_u_v',\n",
       " 'shr_energy_v_v',\n",
       " 'shr_energy_y_v',\n",
       " 'shr_pfp_id_v',\n",
       " 'shr_start_x_v',\n",
       " 'shr_start_y_v',\n",
       " 'shr_start_z_v',\n",
       " 'shr_start_U_v',\n",
       " 'shr_start_V_v',\n",
       " 'shr_dist_v',\n",
       " 'shr_nclus0_v',\n",
       " 'shr_clushitfrac0_v',\n",
       " 'shr_nclus1_v',\n",
       " 'shr_clushitfrac1_v',\n",
       " 'shr_nclus2_v',\n",
       " 'shr_clushitfrac2_v',\n",
       " 'shr_px_v',\n",
       " 'shr_py_v',\n",
       " 'shr_pz_v',\n",
       " 'shr_openangle_v',\n",
       " 'shr_theta_v',\n",
       " 'shr_phi_v',\n",
       " 'shr_pitch_u_v',\n",
       " 'shr_pitch_v_v',\n",
       " 'shr_pitch_y_v',\n",
       " 'shr_tkfit_nhits_v',\n",
       " 'shr_tkfit_start_x_v',\n",
       " 'shr_tkfit_start_y_v',\n",
       " 'shr_tkfit_start_z_v',\n",
       " 'shr_tkfit_start_U_v',\n",
       " 'shr_tkfit_start_V_v',\n",
       " 'shr_tkfit_theta_v',\n",
       " 'shr_tkfit_phi_v',\n",
       " 'shr_tkfit_pitch_u_v',\n",
       " 'shr_tkfit_pitch_v_v',\n",
       " 'shr_tkfit_pitch_y_v',\n",
       " 'shr_tkfit_dedx_u_v',\n",
       " 'shr_tkfit_dedx_v_v',\n",
       " 'shr_tkfit_dedx_y_v',\n",
       " 'shr_tkfit_gap10_dedx_u_v',\n",
       " 'shr_tkfit_gap10_dedx_v_v',\n",
       " 'shr_tkfit_gap10_dedx_y_v',\n",
       " 'shr_tkfit_dedx_nhits_u_v',\n",
       " 'shr_tkfit_dedx_nhits_v_v',\n",
       " 'shr_tkfit_dedx_nhits_y_v',\n",
       " 'shr_spacepoint_start_x_v',\n",
       " 'shr_spacepoint_start_y_v',\n",
       " 'shr_spacepoint_start_z_v',\n",
       " 'shr_spacepoint_start_U_v',\n",
       " 'shr_spacepoint_start_V_v',\n",
       " 'shr_hits_start_U_wire_v',\n",
       " 'shr_hits_start_U_x_v',\n",
       " 'shr_hits_start_V_wire_v',\n",
       " 'shr_hits_start_V_x_v',\n",
       " 'shr_hits_start_Y_wire_v',\n",
       " 'shr_hits_start_Y_x_v']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_formatted_code = \"shr_fields\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shr_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['backtracked_pdg',\n",
       " 'backtracked_e',\n",
       " 'backtracked_purity',\n",
       " 'backtracked_completeness',\n",
       " 'backtracked_overlay_purity',\n",
       " 'backtracked_px',\n",
       " 'backtracked_py',\n",
       " 'backtracked_pz',\n",
       " 'backtracked_start_x',\n",
       " 'backtracked_start_y',\n",
       " 'backtracked_start_z',\n",
       " 'backtracked_start_t',\n",
       " 'backtracked_start_U',\n",
       " 'backtracked_start_V',\n",
       " 'backtracked_start_Y',\n",
       " 'backtracked_sce_start_x',\n",
       " 'backtracked_sce_start_y',\n",
       " 'backtracked_sce_start_z',\n",
       " 'backtracked_sce_start_U',\n",
       " 'backtracked_sce_start_V',\n",
       " 'backtracked_sce_start_Y']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_formatted_code = \"backracked_fields\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "backracked_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CosmicDirAll2DEnds',\n",
       " 'CosmicDirAll2DOvlp',\n",
       " 'CosmicDirAll3D',\n",
       " 'CosmicIP',\n",
       " 'CosmicIPAll2DEnds',\n",
       " 'CosmicIPAll2DOvlp',\n",
       " 'CosmicIPAll3D',\n",
       " 'NeutrinoEnergy0',\n",
       " 'NeutrinoEnergy1',\n",
       " 'NeutrinoEnergy2',\n",
       " 'SliceCaloEnergy0',\n",
       " 'SliceCaloEnergy1',\n",
       " 'SliceCaloEnergy2',\n",
       " 'bdt_cosmic',\n",
       " 'bdt_ext',\n",
       " 'bdt_global',\n",
       " 'bdt_nuNCpi0',\n",
       " 'bdt_numuCC',\n",
       " 'bdt_numuCCpi0',\n",
       " 'best_cosmic_flashmatch_score',\n",
       " 'best_obviouscosmic_flashmatch_score',\n",
       " 'category',\n",
       " 'ccnc',\n",
       " 'cosmic_flashmatch_score_v',\n",
       " 'crthitpe',\n",
       " 'crtveto',\n",
       " 'dmc_boundary',\n",
       " 'dshr_boundary',\n",
       " 'dshr_x_boundary',\n",
       " 'dshr_y_boundary',\n",
       " 'dshr_z_boundary',\n",
       " 'dtrk',\n",
       " 'dtrk_boundary',\n",
       " 'dtrk_x_boundary',\n",
       " 'dtrk_y_boundary',\n",
       " 'dtrk_z_boundary',\n",
       " 'dvtx',\n",
       " 'dvtx_boundary',\n",
       " 'dvtx_x_boundary',\n",
       " 'dvtx_y_boundary',\n",
       " 'dvtx_z_boundary',\n",
       " 'elec_c',\n",
       " 'elec_dist',\n",
       " 'elec_e',\n",
       " 'elec_edep',\n",
       " 'elec_etot',\n",
       " 'elec_p',\n",
       " 'elec_parent',\n",
       " 'elec_vx',\n",
       " 'elec_vy',\n",
       " 'elec_vz',\n",
       " 'endmuonmichel',\n",
       " 'endmuonprocess',\n",
       " 'evgamnhits',\n",
       " 'evlepnhits',\n",
       " 'evneunhits',\n",
       " 'evnhits',\n",
       " 'evnunhits',\n",
       " 'evothnhits',\n",
       " 'evpi0nhits',\n",
       " 'evpi1nhits',\n",
       " 'evpronhits',\n",
       " 'evt',\n",
       " 'extra_energy_y',\n",
       " 'flash_pe',\n",
       " 'flash_time',\n",
       " 'frac_slnoise_pl1',\n",
       " 'gamma1_edep',\n",
       " 'gamma1_etot',\n",
       " 'gamma2_edep',\n",
       " 'gamma2_etot',\n",
       " 'gamma_dist',\n",
       " 'gamma_edep',\n",
       " 'gamma_etot',\n",
       " 'gamma_parent',\n",
       " 'hits_ratio',\n",
       " 'hits_u',\n",
       " 'hits_v',\n",
       " 'hits_y',\n",
       " 'interaction',\n",
       " 'isVtxInFiducial',\n",
       " 'leeweight',\n",
       " 'lep_e',\n",
       " 'matched_E',\n",
       " 'muon_c',\n",
       " 'muon_e',\n",
       " 'muon_p',\n",
       " 'n_pfps',\n",
       " 'n_showers',\n",
       " 'n_showers_contained',\n",
       " 'n_tracks',\n",
       " 'n_tracks_contained',\n",
       " 'nelec',\n",
       " 'nflag_pl1',\n",
       " 'nhits_pl1',\n",
       " 'nmuon',\n",
       " 'nneutron',\n",
       " 'nnoise_pl1',\n",
       " 'npi0',\n",
       " 'npion',\n",
       " 'nproton',\n",
       " 'nslhits_pl1',\n",
       " 'nslice',\n",
       " 'nslnoise_pl1',\n",
       " 'nu_completeness_from_pfp',\n",
       " 'nu_e',\n",
       " 'nu_flashmatch_score',\n",
       " 'nu_pdg',\n",
       " 'nu_pt',\n",
       " 'nu_purity_from_pfp',\n",
       " 'p',\n",
       " 'p_assume_muon',\n",
       " 'pass',\n",
       " 'pass_antibdt_filter',\n",
       " 'pfgamnhits',\n",
       " 'pflepnhits',\n",
       " 'pfneunhits',\n",
       " 'pfnhits',\n",
       " 'pfnplanehits_U',\n",
       " 'pfnplanehits_V',\n",
       " 'pfnplanehits_Y',\n",
       " 'pfnunhits',\n",
       " 'pfothnhits',\n",
       " 'pfp_generation_v',\n",
       " 'pfp_shr_daughters_v',\n",
       " 'pfp_slice_idx',\n",
       " 'pfp_trk_daughters_v',\n",
       " 'pfpdg',\n",
       " 'pfpi0nhits',\n",
       " 'pfpi1nhits',\n",
       " 'pfpronhits',\n",
       " 'pi0_c',\n",
       " 'pi0_dedx1_U',\n",
       " 'pi0_dedx1_V',\n",
       " 'pi0_dedx1_Y',\n",
       " 'pi0_dedx1_fit_U',\n",
       " 'pi0_dedx1_fit_V',\n",
       " 'pi0_dedx1_fit_Y',\n",
       " 'pi0_dedx2_U',\n",
       " 'pi0_dedx2_V',\n",
       " 'pi0_dedx2_Y',\n",
       " 'pi0_dedx2_fit_U',\n",
       " 'pi0_dedx2_fit_V',\n",
       " 'pi0_dedx2_fit_Y',\n",
       " 'pi0_dot1',\n",
       " 'pi0_dot2',\n",
       " 'pi0_e',\n",
       " 'pi0_energy1_U',\n",
       " 'pi0_energy1_V',\n",
       " 'pi0_energy1_Y',\n",
       " 'pi0_energy2_U',\n",
       " 'pi0_energy2_V',\n",
       " 'pi0_energy2_Y',\n",
       " 'pi0_gammadot',\n",
       " 'pi0_mass_U',\n",
       " 'pi0_mass_V',\n",
       " 'pi0_mass_Y',\n",
       " 'pi0_mcgamma0_e',\n",
       " 'pi0_mcgamma0_px',\n",
       " 'pi0_mcgamma0_py',\n",
       " 'pi0_mcgamma0_pz',\n",
       " 'pi0_mcgamma1_e',\n",
       " 'pi0_mcgamma1_px',\n",
       " 'pi0_mcgamma1_py',\n",
       " 'pi0_mcgamma1_pz',\n",
       " 'pi0_mcrcdot0',\n",
       " 'pi0_mcrcdot1',\n",
       " 'pi0_mcrce0',\n",
       " 'pi0_mcrce1',\n",
       " 'pi0_ngamma',\n",
       " 'pi0_nshower',\n",
       " 'pi0_ntrack',\n",
       " 'pi0_p',\n",
       " 'pi0_radlen1',\n",
       " 'pi0_radlen2',\n",
       " 'pi0_rc_vtx_x',\n",
       " 'pi0_rc_vtx_y',\n",
       " 'pi0_rc_vtx_z',\n",
       " 'pi0_shrscore1',\n",
       " 'pi0_shrscore2',\n",
       " 'pion_c',\n",
       " 'pion_e',\n",
       " 'pion_p',\n",
       " 'proton_c',\n",
       " 'proton_e',\n",
       " 'proton_p',\n",
       " 'pt',\n",
       " 'pt_assume_muon',\n",
       " 'reco_nu_vtx_sce_x',\n",
       " 'reco_nu_vtx_sce_y',\n",
       " 'reco_nu_vtx_sce_z',\n",
       " 'reco_nu_vtx_x',\n",
       " 'reco_nu_vtx_y',\n",
       " 'reco_nu_vtx_z',\n",
       " 'run',\n",
       " 'selected',\n",
       " 'shr_bkt_E',\n",
       " 'shr_bkt_completeness',\n",
       " 'shr_bkt_pdg',\n",
       " 'shr_bkt_purity',\n",
       " 'shr_bragg_kaon',\n",
       " 'shr_bragg_mip',\n",
       " 'shr_bragg_mu',\n",
       " 'shr_bragg_p',\n",
       " 'shr_bragg_pion',\n",
       " 'shr_chimu',\n",
       " 'shr_chipr',\n",
       " 'shr_dedx_U',\n",
       " 'shr_dedx_U_cali',\n",
       " 'shr_dedx_V',\n",
       " 'shr_dedx_V_cali',\n",
       " 'shr_dedx_Y',\n",
       " 'shr_dedx_Y_cali',\n",
       " 'shr_distance',\n",
       " 'shr_energy',\n",
       " 'shr_energy_cali',\n",
       " 'shr_energy_tot',\n",
       " 'shr_energy_tot_cali',\n",
       " 'shr_hits_max',\n",
       " 'shr_hits_tot',\n",
       " 'shr_hits_u_tot',\n",
       " 'shr_hits_v_tot',\n",
       " 'shr_hits_y_tot',\n",
       " 'shr_id',\n",
       " 'shr_openangle',\n",
       " 'shr_pca_0',\n",
       " 'shr_pca_1',\n",
       " 'shr_pca_2',\n",
       " 'shr_phi',\n",
       " 'shr_px',\n",
       " 'shr_py',\n",
       " 'shr_pz',\n",
       " 'shr_score',\n",
       " 'shr_start_x',\n",
       " 'shr_start_y',\n",
       " 'shr_start_z',\n",
       " 'shr_theta',\n",
       " 'shr_tkfit_dedx_U',\n",
       " 'shr_tkfit_dedx_V',\n",
       " 'shr_tkfit_dedx_Y',\n",
       " 'shr_tkfit_gap05_dedx_U',\n",
       " 'shr_tkfit_gap05_dedx_V',\n",
       " 'shr_tkfit_gap05_dedx_Y',\n",
       " 'shr_tkfit_gap05_nhits_U',\n",
       " 'shr_tkfit_gap05_nhits_V',\n",
       " 'shr_tkfit_gap05_nhits_Y',\n",
       " 'shr_tkfit_gap10_dedx_U',\n",
       " 'shr_tkfit_gap10_dedx_V',\n",
       " 'shr_tkfit_gap10_dedx_Y',\n",
       " 'shr_tkfit_gap10_nhits_U',\n",
       " 'shr_tkfit_gap10_nhits_V',\n",
       " 'shr_tkfit_gap10_nhits_Y',\n",
       " 'shr_tkfit_nhits_U',\n",
       " 'shr_tkfit_nhits_V',\n",
       " 'shr_tkfit_nhits_Y',\n",
       " 'shr_tkfit_npoints',\n",
       " 'shr_tkfit_npointsvalid',\n",
       " 'shr_tkfit_phi',\n",
       " 'shr_tkfit_start_x',\n",
       " 'shr_tkfit_start_y',\n",
       " 'shr_tkfit_start_z',\n",
       " 'shr_tkfit_theta',\n",
       " 'shr_trkfitmedangle',\n",
       " 'shrclusfrac0',\n",
       " 'shrclusfrac1',\n",
       " 'shrclusfrac2',\n",
       " 'shrmoliereavg',\n",
       " 'shrmoliererms',\n",
       " 'shrsubclusters0',\n",
       " 'shrsubclusters1',\n",
       " 'shrsubclusters2',\n",
       " 'slclustfrac',\n",
       " 'slgamnhits',\n",
       " 'sllepnhits',\n",
       " 'slneunhits',\n",
       " 'slnhits',\n",
       " 'slnunhits',\n",
       " 'slothnhits',\n",
       " 'slpdg',\n",
       " 'slpi0nhits',\n",
       " 'slpi1nhits',\n",
       " 'slpronhits',\n",
       " 'sub',\n",
       " 'swtrig',\n",
       " 'theta',\n",
       " 'tksh_angle',\n",
       " 'tksh_distance',\n",
       " 'topological_score',\n",
       " 'total_hits_y',\n",
       " 'trk_bkt_E',\n",
       " 'trk_bkt_completeness',\n",
       " 'trk_bkt_pdg',\n",
       " 'trk_bkt_purity',\n",
       " 'trk_bragg_kaon',\n",
       " 'trk_bragg_mip',\n",
       " 'trk_bragg_mu',\n",
       " 'trk_bragg_p',\n",
       " 'trk_bragg_pion',\n",
       " 'trk_chimu',\n",
       " 'trk_chimu_best',\n",
       " 'trk_chimu_worst',\n",
       " 'trk_chipr',\n",
       " 'trk_chipr_best',\n",
       " 'trk_chipr_worst',\n",
       " 'trk_distance',\n",
       " 'trk_energy',\n",
       " 'trk_energy_hits_tot',\n",
       " 'trk_energy_muon',\n",
       " 'trk_energy_muon_mcs',\n",
       " 'trk_energy_muon_tot',\n",
       " 'trk_energy_tot',\n",
       " 'trk_hits_max',\n",
       " 'trk_hits_tot',\n",
       " 'trk_hits_u_tot',\n",
       " 'trk_hits_v_tot',\n",
       " 'trk_hits_y_tot',\n",
       " 'trk_id',\n",
       " 'trk_len',\n",
       " 'trk_phi',\n",
       " 'trk_pida',\n",
       " 'trk_score',\n",
       " 'trk_theta',\n",
       " 'trkshrhitdist0',\n",
       " 'trkshrhitdist1',\n",
       " 'trkshrhitdist2',\n",
       " 'truthFiducial',\n",
       " 'weightSpline',\n",
       " 'weights',\n",
       " 'weightsFlux',\n",
       " 'weightsGenie',\n",
       " 'weightsReint'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_formatted_code = \"other_fields\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "other_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CosmicIPAll3D',\n",
       " 'CosmicDirAll3D',\n",
       " 'CosmicIPAll2DEnds',\n",
       " 'CosmicDirAll2DEnds',\n",
       " 'CosmicIPAll2DOvlp',\n",
       " 'CosmicDirAll2DOvlp',\n",
       " 'sllepnhits',\n",
       " 'trk_llr_pid_u_v',\n",
       " 'trk_llr_pid_v_v',\n",
       " 'trk_llr_pid_y_v',\n",
       " 'trk_llr_pid_v',\n",
       " 'trk_llr_pid_score_v']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_formatted_code = \"# search through fields:\\n[f for f in fields if \\\"ll\\\" in f]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# search through fields:\n",
    "[f for f in fields if \"ll\" in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.62 s, sys: 108 ms, total: 2.73 s\n",
      "Wall time: 1.6 s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_formatted_code = \"%%time\\n# For all samples\\nfor k, v in sample_info.items():\\n    # Add fiducial reco sce vtx\\n    v[\\\"daughters\\\"][\\\"reco_fid_vol\\\"] = np.repeat(\\n        helper.is_fid(\\n            *v[\\\"daughters\\\"][\\n                [\\\"reco_nu_vtx_sce_x\\\", \\\"reco_nu_vtx_sce_y\\\", \\\"reco_nu_vtx_sce_z\\\"]\\n            ]\\n            .xs(0, level=\\\"daughter\\\")\\n            .values.T\\n        ),\\n        v[\\\"daughters\\\"][\\\"n_pfps\\\"].xs(0, level=\\\"daughter\\\"),\\n    )\\n    # Add pfp at vtx:\\n    v[\\\"daughters\\\"][\\\"n_pfpvtx\\\"] = v[\\\"daughters\\\"].eval(\\\"trk_distance_v<3 & trk_distance_v>=0\\\")\\n    v[\\\"daughters\\\"][\\\"n_pfpvtx\\\"] = v[\\\"daughters\\\"]['n_pfpvtx'].groupby(\\\"event\\\").transform(sum)\\n    v[\\\"daughters\\\"][\\\"n_pfp_farvtx\\\"] = v[\\\"daughters\\\"].eval(\\\"n_pfps-n_pfpvtx\\\")\\n    \\n    # Add electron candidate check\\n    e_cand_str = 'pfnplanehits_U>0 & pfnplanehits_V>0 & pfnplanehits_Y>0 & trk_score_v<@max_trk_score & shr_tkfit_dedx_nhits_y_v>0'    \\n    data = v[\\\"daughters\\\"][\\n                [\\n                    \\\"pfnplanehits_U\\\", \\\"pfnplanehits_V\\\", \\\"pfnplanehits_Y\\\",\\n                    \\\"trk_score_v\\\",'shr_tkfit_dedx_nhits_y_v',\\n                    \\\"shr_dist_v\\\",\\n                ]\\n            ]\\n    electron_candidate = data.eval(e_cand_str)\\n    e_cand_maxe = data[electron_candidate][\\\"shr_dist_v\\\"].groupby(\\\"event\\\").transform(min) == data[electron_candidate][\\\"shr_dist_v\\\"]\\n    v[\\\"daughters\\\"][\\\"e_candidate\\\"] = False\\n    v[\\\"daughters\\\"].loc[e_cand_maxe[e_cand_maxe == True].index, \\\"e_candidate\\\"] = True\\n    # Add weighted dedx:\\n    dedx_cols = [\\\"shr_tkfit_dedx_u_v\\\",\\n                    \\\"shr_tkfit_dedx_v_v\\\",\\n                    \\\"shr_tkfit_dedx_y_v\\\",\\n                    'shr_tkfit_nhits_v',\\n                    \\\"shr_tkfit_dedx_nhits_u_v\\\",\\n                    \\\"shr_tkfit_dedx_nhits_v_v\\\",\\n                    \\\"shr_tkfit_dedx_nhits_y_v\\\"]\\n    v[\\\"daughters\\\"][dedx_cols]=v[\\\"daughters\\\"][dedx_cols].clip(lower=0)\\n    str_dedx_weighted_mean='(shr_tkfit_dedx_u_v*shr_tkfit_dedx_nhits_u_v+shr_tkfit_dedx_v_v*shr_tkfit_dedx_nhits_v_v+shr_tkfit_dedx_y_v*shr_tkfit_dedx_nhits_y_v)/(shr_tkfit_dedx_nhits_u_v+shr_tkfit_dedx_nhits_v_v+shr_tkfit_dedx_nhits_y_v)'\\n    v[\\\"daughters\\\"]['shr_tkfit_dedx_wm_v']= v[\\\"daughters\\\"].eval(str_dedx_weighted_mean)\\n    # Add weigthed pid chi mu/pr:\\n    pid_chi_cols = [\\\"trk_pid_chipr_v\\\",\\n    \\\"trk_pid_chimu_v\\\",\\n    \\\"trk_pid_chipr_v_v\\\",\\n    \\\"trk_pid_chimu_v_v\\\",\\n    \\\"trk_pid_chipr_u_v\\\",\\n    \\\"trk_pid_chimu_u_v\\\"]\\n    v[\\\"daughters\\\"][pid_chi_cols]=v[\\\"daughters\\\"][pid_chi_cols].clip(upper=pid_upper_clip)\\n    str_pidmu_weighted_mean='(trk_pid_chimu_v*pfnplanehits_Y+trk_pid_chimu_v_v*pfnplanehits_V+trk_pid_chimu_u_v*pfnplanehits_U)/pfnhits'\\n    v[\\\"daughters\\\"]['trk_pid_chimu_wm_v']= v[\\\"daughters\\\"].eval(str_pidmu_weighted_mean)\\n    str_pidpr_weighted_mean='(trk_pid_chipr_v*pfnplanehits_Y+trk_pid_chipr_v_v*pfnplanehits_V+trk_pid_chipr_u_v*pfnplanehits_U)/pfnhits'\\n    v[\\\"daughters\\\"]['trk_pid_chipr_wm_v']= v[\\\"daughters\\\"].eval(str_pidpr_weighted_mean)\\n    # Add the number of hits per length:\\n    v[\\\"daughters\\\"]['hits_per_tklen']= v[\\\"daughters\\\"].eval('pfnhits/trk_len_v')\\n    \\n    # Drop columns I do not need anymore:\\n    drop_cols = [\\n    \\\"pfnplanehits_U\\\",\\n    \\\"pfnplanehits_V\\\",\\n    \\\"pfnplanehits_Y\\\",\\n    'pfnhits',\\n    \\\"shr_tkfit_dedx_u_v\\\",\\n    \\\"shr_tkfit_dedx_v_v\\\",\\n    \\\"shr_tkfit_nhits_v\\\",\\n    \\\"shr_tkfit_dedx_nhits_u_v\\\",\\n    \\\"shr_tkfit_dedx_nhits_v_v\\\",    \\n    \\\"trk_pid_chipr_v_v\\\",\\n    \\\"trk_pid_chimu_v_v\\\",\\n    \\\"trk_pid_chipr_u_v\\\",\\n    \\\"trk_pid_chimu_u_v\\\",\\n]\\nfor c in drop_cols:\\n    if c in v[\\\"daughters\\\"].columns:\\n        v[\\\"daughters\\\"].drop(c, inplace=True, axis=1)\\n    else:\\n        print(c, \\\" was not in dataframe!\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "# For all samples\n",
    "for k, v in sample_info.items():\n",
    "    # Add fiducial reco sce vtx\n",
    "    v[\"daughters\"][\"reco_fid_vol\"] = np.repeat(\n",
    "        helper.is_fid(\n",
    "            *v[\"daughters\"][\n",
    "                [\"reco_nu_vtx_sce_x\", \"reco_nu_vtx_sce_y\", \"reco_nu_vtx_sce_z\"]\n",
    "            ]\n",
    "            .xs(0, level=\"daughter\")\n",
    "            .values.T\n",
    "        ),\n",
    "        v[\"daughters\"][\"n_pfps\"].xs(0, level=\"daughter\"),\n",
    "    )\n",
    "    # Add pfp at vtx:\n",
    "    v[\"daughters\"][\"n_pfpvtx\"] = v[\"daughters\"].eval(\"trk_distance_v<3 & trk_distance_v>=0\")\n",
    "    v[\"daughters\"][\"n_pfpvtx\"] = v[\"daughters\"]['n_pfpvtx'].groupby(\"event\").transform(sum)\n",
    "    v[\"daughters\"][\"n_pfp_farvtx\"] = v[\"daughters\"].eval(\"n_pfps-n_pfpvtx\")\n",
    "    \n",
    "    # Add electron candidate check\n",
    "    e_cand_str = 'pfnplanehits_U>0 & pfnplanehits_V>0 & pfnplanehits_Y>0 & trk_score_v<@max_trk_score & shr_tkfit_dedx_nhits_y_v>0'    \n",
    "    data = v[\"daughters\"][\n",
    "                [\n",
    "                    \"pfnplanehits_U\", \"pfnplanehits_V\", \"pfnplanehits_Y\",\n",
    "                    \"trk_score_v\",'shr_tkfit_dedx_nhits_y_v',\n",
    "                    \"shr_dist_v\",\n",
    "                ]\n",
    "            ]\n",
    "    electron_candidate = data.eval(e_cand_str)\n",
    "    e_cand_maxe = data[electron_candidate][\"shr_dist_v\"].groupby(\"event\").transform(min) == data[electron_candidate][\"shr_dist_v\"]\n",
    "    v[\"daughters\"][\"e_candidate\"] = False\n",
    "    v[\"daughters\"].loc[e_cand_maxe[e_cand_maxe == True].index, \"e_candidate\"] = True\n",
    "    # Add weighted dedx:\n",
    "    dedx_cols = [\"shr_tkfit_dedx_u_v\",\n",
    "                    \"shr_tkfit_dedx_v_v\",\n",
    "                    \"shr_tkfit_dedx_y_v\",\n",
    "                    'shr_tkfit_nhits_v',\n",
    "                    \"shr_tkfit_dedx_nhits_u_v\",\n",
    "                    \"shr_tkfit_dedx_nhits_v_v\",\n",
    "                    \"shr_tkfit_dedx_nhits_y_v\"]\n",
    "    v[\"daughters\"][dedx_cols]=v[\"daughters\"][dedx_cols].clip(lower=0)\n",
    "    str_dedx_weighted_mean='(shr_tkfit_dedx_u_v*shr_tkfit_dedx_nhits_u_v+shr_tkfit_dedx_v_v*shr_tkfit_dedx_nhits_v_v+shr_tkfit_dedx_y_v*shr_tkfit_dedx_nhits_y_v)/(shr_tkfit_dedx_nhits_u_v+shr_tkfit_dedx_nhits_v_v+shr_tkfit_dedx_nhits_y_v)'\n",
    "    v[\"daughters\"]['shr_tkfit_dedx_wm_v']= v[\"daughters\"].eval(str_dedx_weighted_mean)\n",
    "    # Add weigthed pid chi mu/pr:\n",
    "    pid_chi_cols = [\"trk_pid_chipr_v\",\n",
    "    \"trk_pid_chimu_v\",\n",
    "    \"trk_pid_chipr_v_v\",\n",
    "    \"trk_pid_chimu_v_v\",\n",
    "    \"trk_pid_chipr_u_v\",\n",
    "    \"trk_pid_chimu_u_v\"]\n",
    "    v[\"daughters\"][pid_chi_cols]=v[\"daughters\"][pid_chi_cols].clip(upper=pid_upper_clip)\n",
    "    str_pidmu_weighted_mean='(trk_pid_chimu_v*pfnplanehits_Y+trk_pid_chimu_v_v*pfnplanehits_V+trk_pid_chimu_u_v*pfnplanehits_U)/pfnhits'\n",
    "    v[\"daughters\"]['trk_pid_chimu_wm_v']= v[\"daughters\"].eval(str_pidmu_weighted_mean)\n",
    "    str_pidpr_weighted_mean='(trk_pid_chipr_v*pfnplanehits_Y+trk_pid_chipr_v_v*pfnplanehits_V+trk_pid_chipr_u_v*pfnplanehits_U)/pfnhits'\n",
    "    v[\"daughters\"]['trk_pid_chipr_wm_v']= v[\"daughters\"].eval(str_pidpr_weighted_mean)\n",
    "    # Add the number of hits per length:\n",
    "    v[\"daughters\"]['hits_per_tklen']= v[\"daughters\"].eval('pfnhits/trk_len_v')\n",
    "    \n",
    "    # Drop columns I do not need anymore:\n",
    "    drop_cols = [\n",
    "    \"pfnplanehits_U\",\n",
    "    \"pfnplanehits_V\",\n",
    "    \"pfnplanehits_Y\",\n",
    "    'pfnhits',\n",
    "    \"shr_tkfit_dedx_u_v\",\n",
    "    \"shr_tkfit_dedx_v_v\",\n",
    "    \"shr_tkfit_nhits_v\",\n",
    "    \"shr_tkfit_dedx_nhits_u_v\",\n",
    "    \"shr_tkfit_dedx_nhits_v_v\",    \n",
    "    \"trk_pid_chipr_v_v\",\n",
    "    \"trk_pid_chimu_v_v\",\n",
    "    \"trk_pid_chipr_u_v\",\n",
    "    \"trk_pid_chimu_u_v\",\n",
    "]\n",
    "for c in drop_cols:\n",
    "    if c in v[\"daughters\"].columns:\n",
    "        v[\"daughters\"].drop(c, inplace=True, axis=1)\n",
    "    else:\n",
    "        print(c, \" was not in dataframe!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wouter/Binaries/miniconda3/envs/uproot/lib/python3.7/site-packages/numpy/linalg/linalg.py:2512: RuntimeWarning: overflow encountered in multiply\n",
      "  s = (x.conj() * x).real\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.35 s, sys: 424 ms, total: 1.77 s\n",
      "Wall time: 970 ms\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_formatted_code = \"%%time\\n# For MC samples\\nfor k, v in sample_info.items():\\n    if k not in helper.data_samples:\\n        \\n        # Correct the LEE weight using the splineweight\\n        v['daughters'][\\\"leeweight\\\"]*=v['daughters'][\\\"weightSpline\\\"]\\n        \\n        # Add distance between reco_sce and true vertex\\n        data = (\\n            v[\\\"daughters\\\"][\\n                [\\n                    \\\"reco_nu_vtx_sce_x\\\",\\n                    \\\"reco_nu_vtx_sce_y\\\",\\n                    \\\"reco_nu_vtx_sce_z\\\",\\n                    \\\"true_nu_vtx_x\\\",\\n                    \\\"true_nu_vtx_y\\\",\\n                    \\\"true_nu_vtx_z\\\",\\n                ]\\n            ]\\n            .xs(0, level=\\\"daughter\\\")\\n            .values.T\\n        )\\n        data[0]-=x_sce_magic # Correct x location for the 0.6 sign error\\n        \\n        v[\\\"daughters\\\"][\\\"true_vtx_distance\\\"] = np.repeat(\\n            np.linalg.norm(data[0:3] - data[3:6], axis=0),\\n            v[\\\"daughters\\\"][\\\"n_pfps\\\"].xs(0, level=\\\"daughter\\\"),\\n        )\\n        # Cross-check vtx distance\\n        data = (\\n            v[\\\"daughters\\\"][\\n                [\\n                    \\\"true_nu_vtx_sce_x\\\",\\n                    \\\"true_nu_vtx_sce_y\\\",\\n                    \\\"true_nu_vtx_sce_z\\\",\\n                    \\\"reco_nu_vtx_x\\\",\\n                    \\\"reco_nu_vtx_y\\\",\\n                    \\\"reco_nu_vtx_z\\\",\\n                ]\\n            ]\\n            .xs(0, level=\\\"daughter\\\")\\n            .values.T\\n        )\\n        v[\\\"daughters\\\"][\\\"true_vtx_distance_check\\\"] = np.repeat(\\n            np.linalg.norm(data[0:3] - data[3:6], axis=0),\\n            v[\\\"daughters\\\"][\\\"n_pfps\\\"].xs(0, level=\\\"daughter\\\"),\\n        )\\n        # Add the distance between the true neutrino vertex and the reconstructed shower start point\\n        data = (\\n            v[\\\"daughters\\\"][\\n                [\\n                    \\\"true_nu_vtx_sce_x\\\",\\n                    \\\"true_nu_vtx_sce_y\\\",\\n                    \\\"true_nu_vtx_sce_z\\\",\\n                    \\\"shr_tkfit_start_x_v\\\",\\n                    \\\"shr_tkfit_start_y_v\\\",\\n                    \\\"shr_tkfit_start_z_v\\\",\\n                ]\\n            ]\\n            .values.T\\n        )\\n        v[\\\"daughters\\\"][\\\"true_shower_distance\\\"] = np.linalg.norm(data[0:3] - data[3:6], axis=0)\\n        \\n        # Add the modified purity/completeness to account for overlay.\\n        overlay_mask = v[\\\"daughters\\\"].eval('backtracked_overlay_purity>backtracked_purity')\\n        v[\\\"daughters\\\"].loc[overlay_mask, 'backtracked_pdg'] = 0\\n        v[\\\"daughters\\\"].loc[overlay_mask, 'backtracked_purity'] = v[\\\"daughters\\\"].loc[overlay_mask, 'backtracked_overlay_purity']\\n        v[\\\"daughters\\\"].loc[overlay_mask, 'backtracked_completeness'] = 0\\n        \\n        # Drop some stuff you do not need anymore\\n        drop_cols = ['backtracked_overlay_purity',\\n                     \\\"true_nu_vtx_sce_y\\\",\\n                     \\\"true_nu_vtx_sce_z\\\",\\n                     \\\"reco_nu_vtx_y\\\",\\n                     \\\"reco_nu_vtx_z\\\"]\\n        for c in drop_cols:\\n            if c in v[\\\"daughters\\\"].columns:\\n                v[\\\"daughters\\\"].drop(c, inplace=True, axis=1)\\n            else:\\n                print(c, \\\" was not in dataframe!\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "# For MC samples\n",
    "for k, v in sample_info.items():\n",
    "    if k not in helper.data_samples:\n",
    "        \n",
    "        # Correct the LEE weight using the splineweight\n",
    "        v['daughters'][\"leeweight\"]*=v['daughters'][\"weightSpline\"]\n",
    "        \n",
    "        # Add distance between reco_sce and true vertex\n",
    "        data = (\n",
    "            v[\"daughters\"][\n",
    "                [\n",
    "                    \"reco_nu_vtx_sce_x\",\n",
    "                    \"reco_nu_vtx_sce_y\",\n",
    "                    \"reco_nu_vtx_sce_z\",\n",
    "                    \"true_nu_vtx_x\",\n",
    "                    \"true_nu_vtx_y\",\n",
    "                    \"true_nu_vtx_z\",\n",
    "                ]\n",
    "            ]\n",
    "            .xs(0, level=\"daughter\")\n",
    "            .values.T\n",
    "        )\n",
    "        data[0]-=x_sce_magic # Correct x location for the 0.6 sign error\n",
    "        \n",
    "        v[\"daughters\"][\"true_vtx_distance\"] = np.repeat(\n",
    "            np.linalg.norm(data[0:3] - data[3:6], axis=0),\n",
    "            v[\"daughters\"][\"n_pfps\"].xs(0, level=\"daughter\"),\n",
    "        )\n",
    "        # Cross-check vtx distance\n",
    "        data = (\n",
    "            v[\"daughters\"][\n",
    "                [\n",
    "                    \"true_nu_vtx_sce_x\",\n",
    "                    \"true_nu_vtx_sce_y\",\n",
    "                    \"true_nu_vtx_sce_z\",\n",
    "                    \"reco_nu_vtx_x\",\n",
    "                    \"reco_nu_vtx_y\",\n",
    "                    \"reco_nu_vtx_z\",\n",
    "                ]\n",
    "            ]\n",
    "            .xs(0, level=\"daughter\")\n",
    "            .values.T\n",
    "        )\n",
    "        v[\"daughters\"][\"true_vtx_distance_check\"] = np.repeat(\n",
    "            np.linalg.norm(data[0:3] - data[3:6], axis=0),\n",
    "            v[\"daughters\"][\"n_pfps\"].xs(0, level=\"daughter\"),\n",
    "        )\n",
    "        # Add the distance between the true neutrino vertex and the reconstructed shower start point\n",
    "        data = (\n",
    "            v[\"daughters\"][\n",
    "                [\n",
    "                    \"true_nu_vtx_sce_x\",\n",
    "                    \"true_nu_vtx_sce_y\",\n",
    "                    \"true_nu_vtx_sce_z\",\n",
    "                    \"shr_tkfit_start_x_v\",\n",
    "                    \"shr_tkfit_start_y_v\",\n",
    "                    \"shr_tkfit_start_z_v\",\n",
    "                ]\n",
    "            ]\n",
    "            .values.T\n",
    "        )\n",
    "        v[\"daughters\"][\"true_shower_distance\"] = np.linalg.norm(data[0:3] - data[3:6], axis=0)\n",
    "        \n",
    "        # Add the modified purity/completeness to account for overlay.\n",
    "        overlay_mask = v[\"daughters\"].eval('backtracked_overlay_purity>backtracked_purity')\n",
    "        v[\"daughters\"].loc[overlay_mask, 'backtracked_pdg'] = 0\n",
    "        v[\"daughters\"].loc[overlay_mask, 'backtracked_purity'] = v[\"daughters\"].loc[overlay_mask, 'backtracked_overlay_purity']\n",
    "        v[\"daughters\"].loc[overlay_mask, 'backtracked_completeness'] = 0\n",
    "        \n",
    "        # Drop some stuff you do not need anymore\n",
    "        drop_cols = ['backtracked_overlay_purity',\n",
    "                     \"true_nu_vtx_sce_y\",\n",
    "                     \"true_nu_vtx_sce_z\",\n",
    "                     \"reco_nu_vtx_y\",\n",
    "                     \"reco_nu_vtx_z\"]\n",
    "        for c in drop_cols:\n",
    "            if c in v[\"daughters\"].columns:\n",
    "                v[\"daughters\"].drop(c, inplace=True, axis=1)\n",
    "            else:\n",
    "                print(c, \" was not in dataframe!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# For MC samples, fields needed as training labels:\n",
    "for k, v in sample_info.items():\n",
    "    if k in helper.mc_samples:\n",
    "        # Add training labels and weights\n",
    "        e_cand = v[\"daughters\"]['e_candidate']\n",
    "        e_good = v[\"daughters\"].eval('e_candidate & abs(backtracked_pdg)==11 & backtracked_purity>0.75 & backtracked_completeness>0.5')\n",
    "        e_cand_bad = v[\"daughters\"].eval('e_candidate & abs(backtracked_pdg)!=11')\n",
    "        other_bad = v[\"daughters\"].eval('~e_candidate & (abs(backtracked_pdg)==13 | backtracked_pdg==22 | backtracked_pdg==0)')\n",
    "        \n",
    "        v[\"daughters\"]['train_weight'] = v[\"daughters\"].eval('weightSpline+leeweight*@lee_focus') # weight low energy electrons a bit higher\n",
    "        v[\"daughters\"]['train_weight'] = v[\"daughters\"].eval('train_weight*(1+(150<shr_energy_y_v<400)*@lee_focus)') # weight low energy electrons a bit higher\n",
    "        \n",
    "        v[\"daughters\"].loc[e_good, \"train_weight\"] *= 5 # can be tuned\n",
    "        \n",
    "        v[\"daughters\"]['train_label'] = True\n",
    "        v[\"daughters\"].loc[e_cand_bad, \"train_label\"] = False\n",
    "        v[\"daughters\"].loc[other_bad, \"train_label\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case we train on external data:\n",
    "sample_info[\"Off\"][\"daughters\"][\"nueccinc\"] = False\n",
    "sample_info[\"Off\"][\"daughters\"][\"train_weight\"] = 1\n",
    "low_e_shr = sample_info[\"Off\"][\"daughters\"].eval(\"shr_energy_y_v<0.4\")\n",
    "sample_info[\"Off\"][\"daughters\"].loc[low_e_shr, \"train_weight\"] *= 5  # can be tuned\n",
    "sample_info[\"Off\"][\"daughters\"][\"train_label\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality cuts / Pre-selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_preselect = (\n",
    "    \"e_candidate & reco_fid_vol & slclustfrac>@min_cluster_frac & ~crtveto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Passing rate pre-selection\n",
    "for k, v in sample_info.items():\n",
    "    v[\"daughters\"][\"preselect\"] = v[\"daughters\"].eval(\n",
    "        query_preselect\n",
    "    )\n",
    "    v[\"daughters\"][\"preselect\"] = v[\"daughters\"][\"preselect\"].groupby(\"event\").transform(max)\n",
    "    \n",
    "    pass_rate = sum(v[\"daughters\"].eval(\"e_candidate & preselect\"))/v['numentries']\n",
    "    print(k, \"\\t{:.2f}%\".format(pass_rate * 100))\n",
    "    \n",
    "# Passing rate signal, weights applied!\n",
    "pass_rate = sum(sample_info[\"NUE\"]['daughters'].eval('(e_candidate & preselect)*weightSpline*nueccinc'))/sum(sample_info[\"NUE\"][\"mc\"]['weightSpline']*sample_info['NUE']['nueccinc'] )\n",
    "print(\"Nue signal passing the preselection \\t{:.2f}%\".format(pass_rate * 100))\n",
    "nue_pass = sum(sample_info[\"NUE\"]['daughters'].eval('(e_candidate & preselect)*nueccinc'))*sample_info[\"NUE\"]['scaling']*pot_scale\n",
    "print(\"Nue Intrinsic signal passing: {0:0.3f} per {1:0.2g} POT\".format(nue_pass,pot_target))\n",
    "lee_pass = sum(sample_info[\"NUE\"]['daughters'].eval('(e_candidate & preselect)*leeweight*nueccinc'))*sample_info[\"NUE\"]['scaling']*pot_scale\n",
    "print(\"Nue LEE signal passing: {0:0.3f} per {1:0.2g} POT\".format(lee_pass,pot_target))\n",
    "\n",
    "## Calculate the purity:\n",
    "purity_denom = (\n",
    "    sum(sample_info[\"MC\"][\"daughters\"].eval(\"(e_candidate & preselect)*weightSpline\"))\n",
    "    * sample_info[\"MC\"][\"scaling\"]\n",
    ")\n",
    "purity_denom += (\n",
    "    sum(sample_info[\"DRT\"][\"daughters\"].eval(\"(e_candidate & preselect)*weightSpline\"))\n",
    "    * sample_info[\"DRT\"][\"scaling\"]\n",
    ")\n",
    "purity_denom += (\n",
    "    sum(sample_info[\"Off\"][\"daughters\"].eval(\"(e_candidate & preselect)\")) * sample_info[\"Off\"][\"scaling\"]\n",
    ")\n",
    "\n",
    "purity_mc = (\n",
    "    sum(sample_info[\"NUE\"][\"daughters\"].eval(\"(e_candidate & preselect)*weightSpline*nueccinc\"))\n",
    "    * sample_info[\"NUE\"][\"scaling\"]\n",
    "    / purity_denom\n",
    ")\n",
    "purity_data = (\n",
    "    sum(sample_info[\"NUE\"][\"daughters\"].eval(\"(e_candidate & preselect)*weightSpline*nueccinc\"))\n",
    "    * sample_info[\"NUE\"][\"scaling\"]\n",
    "    / sum(sample_info[\"On\"][\"daughters\"].eval(\"(e_candidate & preselect)\"))\n",
    ")\n",
    "print(\n",
    "    \"Purity MC: {:.1f}%\\nData/MC-ratio: {:.2f}\\n\".format(\n",
    "        purity_mc * 100,\n",
    "        sum(sample_info[\"On\"][\"daughters\"].eval(\"(e_candidate & preselect)\")) / purity_denom,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_train_electron = [\n",
    "    # \"topological_score\",\n",
    "    # \"n_pfpvtx\",\n",
    "    \"n_showers\",\n",
    "    # \"n_tracks\",\n",
    "    # \"trk_score_v\",\n",
    "    # \"trk_len_v\",\n",
    "    \"trk_pid_chipr_v\",\n",
    "    \"trk_pid_chimu_v\",\n",
    "    \"trk_min_cos\",\n",
    "    \"hits_per_tklen\",\n",
    "    \"shr_dist_v\",\n",
    "    \"shr_energy_y_v\",\n",
    "    # \"shr_openangle_v\",\n",
    "    # \"shr_tkfit_theta_v\",\n",
    "    # \"shr_tkfit_phi_v\",\n",
    "    \"shr_tkfit_dedx_wm_v\",\n",
    "    \"shr_tkfit_dedx_y_v\",\n",
    "    # \"shr_tkfit_dedx_nhits_y_v\",\n",
    "    ##\"train_weight\",\n",
    "    ##\"train_label\",\n",
    "]\n",
    "col_train_other = [\n",
    "    # \"topological_score\",\n",
    "    # \"n_showers\",\n",
    "    # \"n_tracks\",\n",
    "    # \"n_pfpvtx\",\n",
    "    \"trk_score_v\",\n",
    "    \"trk_distance_v\",\n",
    "    \"trk_theta_v\",\n",
    "    # \"trk_phi_v\",\n",
    "    \"trk_len_v\",\n",
    "    \"trk_pid_chimu_wm_v\",\n",
    "    \"trk_pid_chipr_wm_v\",\n",
    "    # \"trk_min_cos\",\n",
    "    # \"hits_per_tklen\",\n",
    "    \"shr_energy_y_v\",\n",
    "    # \"shr_openangle_v\",\n",
    "    \"shr_tkfit_dedx_wm_v\",\n",
    "    ##\"train_weight\",\n",
    "    ##\"train_label\",\n",
    "]\n",
    "\n",
    "col_train_event = [\n",
    "    \"topological_score\",\n",
    "    # \"n_showers\",\n",
    "    # \"n_tracks\",\n",
    "    # \"n_pfpvtx\",\n",
    "    \"n_pfp_farvtx\",\n",
    "    \"hits_ratio\",\n",
    "    \"contained_fraction\",\n",
    "    \"score\",\n",
    "    # \"score_other_max\",\n",
    "    \"score_other_min\",\n",
    "    \"score_other_mean\",\n",
    "    \"CosmicIP\"\n",
    "    # \"nu_flashmatch_score\",\n",
    "    ## nueccinc\n",
    "    ## train_weight -> use the train weight of the electron candidate\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Electron training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q = \"preselect & e_candidate\"\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for k in train_samples:\n",
    "    X = sample_info[k][\"daughters\"].query(train_q)[col_train_electron]\n",
    "    Y = sample_info[k][\"daughters\"].query(train_q)[[\"train_label\", \"train_weight\"]]\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X, Y, test_size=test_size, random_state=seed\n",
    "    )\n",
    "    X_train.append(X_tr)\n",
    "    X_test.append(X_te)\n",
    "    y_train.append(y_tr)\n",
    "    y_test.append(y_te)\n",
    "\n",
    "# Merge our two samples\n",
    "X_train = pd.concat(X_train).reset_index(drop=True)\n",
    "y_train = pd.concat(y_train).reset_index(drop=True)\n",
    "X_test = pd.concat(X_test).reset_index(drop=True)\n",
    "y_test = pd.concat(y_test).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model no training data\n",
    "if retrain:\n",
    "    model_e = XGBClassifier(max_depth=5)\n",
    "    model_e.fit(X_train, y_train[\"train_label\"], sample_weight=y_train[\"train_weight\"])\n",
    "    dump(model_e, model_dir + \"model_e.pckl\")\n",
    "else:\n",
    "    model_e = load(model_dir + \"model_e.pckl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model_e.predict(X_test)\n",
    "target_names = [\"electron\", \"non_electron\"]\n",
    "print(classification_report(y_test[\"train_label\"], y_pred, target_names=target_names))\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test[\"train_label\"], predictions)\n",
    "print(\"Test accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred_train = model_e.predict(X_train)\n",
    "predictions = [round(value) for value in y_pred_train]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_train[\"train_label\"], predictions)\n",
    "print(\"Train accuracy: %.2f%%\\n\" % (accuracy * 100.0))\n",
    "\n",
    "importances = model_e.feature_importances_\n",
    "sort = np.argsort(-importances)\n",
    "\n",
    "for i, (n, im) in enumerate(zip(np.array(col_train_electron)[sort], importances[sort])):\n",
    "    print(\"%d. feature %s (%f)\" % (i + 1, n, im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(8, 4))\n",
    "\n",
    "y_pred = model_e.predict_proba(X_test).T[1]\n",
    "fpr, tpr, _ = roc_curve(y_test[\"train_label\"], y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "ax[0].hist(\n",
    "    y_pred[y_test[\"train_label\"] == 0],\n",
    "    alpha=0.5,\n",
    "    bins=50,\n",
    "    range=(0, 1),\n",
    "    label=\"no electrons\",\n",
    "    density=False,\n",
    ")\n",
    "ax[0].hist(\n",
    "    y_pred[(y_test[\"train_label\"] == 1) & (y_test[\"train_weight\"] > 2)],\n",
    "    alpha=0.5,\n",
    "    bins=50,\n",
    "    range=(0, 1),\n",
    "    label=\"good electrons\",\n",
    "    density=False,\n",
    ")\n",
    "ax[0].hist(\n",
    "    y_pred[(y_test[\"train_label\"] == 1) & (y_test[\"train_weight\"] < 2)],\n",
    "    alpha=0.5,\n",
    "    bins=50,\n",
    "    range=(0, 1),\n",
    "    label=\"bad electrons\",\n",
    "    density=False,\n",
    ")\n",
    "ax[0].legend(loc=\"upper left\")\n",
    "ax[0].set_xlim(0, 1)\n",
    "ax[0].set_xlabel(\"Electron identification\")\n",
    "ax[0].set_ylabel(\"Entries per bin\")\n",
    "ax[0].set_title(\"Electron Candidate XGB\")\n",
    "\n",
    "ax[1].plot(fpr, tpr, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(output_dir + \"e_bdt_test.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other daughters training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q = \"preselect & ~e_candidate\"\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for k in train_samples:\n",
    "    X = sample_info[k][\"daughters\"].query(train_q)[col_train_other]\n",
    "    Y = sample_info[k][\"daughters\"].query(train_q)[[\"train_label\", \"train_weight\"]]\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X, Y, test_size=test_size, random_state=seed\n",
    "    )\n",
    "    X_train.append(X_tr)\n",
    "    X_test.append(X_te)\n",
    "    y_train.append(y_tr)\n",
    "    y_test.append(y_te)\n",
    "\n",
    "# Merge our two samples\n",
    "X_train = pd.concat(X_train).reset_index(drop=True)\n",
    "y_train = pd.concat(y_train).reset_index(drop=True)\n",
    "X_test = pd.concat(X_test).reset_index(drop=True)\n",
    "y_test = pd.concat(y_test).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model on training data\n",
    "if retrain:\n",
    "    model_d = XGBClassifier(max_depth=5)\n",
    "    model_d.fit(X_train, y_train[\"train_label\"], sample_weight=y_train[\"train_weight\"])\n",
    "    dump(model_d, model_dir + \"model_d.pckl\")\n",
    "else:\n",
    "    model_d = load(model_dir + \"model_d.pckl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model_d.predict(X_test)\n",
    "target_names = [\"proton, pion, ...\", \"muon, overlay, photon\"]\n",
    "print(classification_report(y_test[\"train_label\"], y_pred, target_names=target_names))\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test[\"train_label\"], predictions)\n",
    "print(\"Test accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred_train = model_d.predict(X_train)\n",
    "predictions = [round(value) for value in y_pred_train]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_train[\"train_label\"], predictions)\n",
    "print(\"Train accuracy: %.2f%%\\n\" % (accuracy * 100.0))\n",
    "\n",
    "importances = model_d.feature_importances_\n",
    "sort = np.argsort(-importances)\n",
    "\n",
    "for i, (n, im) in enumerate(zip(np.array(col_train_other)[sort], importances[sort])):\n",
    "    print(\"%d. feature %s (%f)\" % (i + 1, n, im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(8, 4))\n",
    "\n",
    "y_pred = model_d.predict_proba(X_test).T[1]\n",
    "fpr, tpr, _ = roc_curve(y_test[\"train_label\"], y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "ax[0].hist(\n",
    "    y_pred[y_test[\"train_label\"] == 0],\n",
    "    alpha=0.5,\n",
    "    bins=50,\n",
    "    range=(0, 1),\n",
    "    label=\"muon, overlay, photon\",\n",
    "    density=False,\n",
    ")\n",
    "ax[0].hist(\n",
    "    y_pred[y_test[\"train_label\"] == 1],\n",
    "    alpha=0.5,\n",
    "    bins=50,\n",
    "    range=(0, 1),\n",
    "    label=\"proton, pion, ...\",\n",
    "    density=False,\n",
    ")\n",
    "ax[0].legend(loc=\"upper left\")\n",
    "ax[0].set_xlim(0, 1)\n",
    "ax[0].set_xlabel(\"Daughter identification\")\n",
    "ax[0].set_ylabel(\"Entries per bin\")\n",
    "ax[0].set_title(\"Daughter XGB\")\n",
    "\n",
    "ax[1].plot(fpr, tpr, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(output_dir + \"daughter_bdt_test.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply models on the samples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# add the columns for each daughter (all samples)\n",
    "for k, v in sample_info.items():\n",
    "    v[\"daughters\"][\"score\"] = -1\n",
    "    mask_e_cand = v[\"daughters\"].eval(\"preselect & e_candidate\")\n",
    "    v[\"daughters\"].loc[mask_e_cand, \"score\"] = model_e.predict_proba(\n",
    "        v[\"daughters\"][col_train_electron][mask_e_cand]\n",
    "    ).T[1]\n",
    "    mask_d = v[\"daughters\"].eval(\"preselect & ~e_candidate\")\n",
    "    v[\"daughters\"].loc[mask_d, \"score\"] = model_d.predict_proba(\n",
    "        v[\"daughters\"][col_train_other][mask_d]\n",
    "    ).T[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# First we need to add some columns:\n",
    "for k, v in sample_info.items():    \n",
    "    mask_e = v[\"daughters\"].eval(\"preselect & e_candidate & n_pfps>1\")\n",
    "    v[\"daughters\"][\"score_other_max\"] = 1\n",
    "    v[\"daughters\"].loc[mask_e, \"score_other_max\"] = (\n",
    "        v[\"daughters\"]\n",
    "        .query(\"~e_candidate & preselect\")[\"score\"]\n",
    "        .groupby(\"event\")\n",
    "        .max()\n",
    "        .values\n",
    "    )\n",
    "    v[\"daughters\"][\"score_other_mean\"] = 0.95\n",
    "    v[\"daughters\"].loc[mask_e, \"score_other_mean\"] = (\n",
    "        v[\"daughters\"]\n",
    "        .query(\"~e_candidate & preselect\")[\"score\"]\n",
    "        .groupby(\"event\")\n",
    "        .mean()\n",
    "        .values\n",
    "    )\n",
    "    v[\"daughters\"][\"score_other_min\"] = 0.9\n",
    "    v[\"daughters\"].loc[mask_e, \"score_other_min\"] = (\n",
    "        v[\"daughters\"]\n",
    "        .query(\"~e_candidate & preselect\")[\"score\"]\n",
    "        .groupby(\"event\")\n",
    "        .min()\n",
    "        .values\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q = \"preselect & e_candidate\"\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for k in train_samples:\n",
    "    X = sample_info[k][\"daughters\"].query(train_q)[col_train_event]\n",
    "    Y = sample_info[k][\"daughters\"].query(train_q)[[\"nueccinc\", \"train_weight\"]]\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X, Y, test_size=test_size, random_state=seed\n",
    "    )\n",
    "    X_train.append(X_tr)\n",
    "    X_test.append(X_te)\n",
    "    y_train.append(y_tr)\n",
    "    y_test.append(y_te)\n",
    "\n",
    "# Merge our two samples\n",
    "X_train = pd.concat(X_train).reset_index(drop=True)\n",
    "y_train = pd.concat(y_train).reset_index(drop=True)\n",
    "X_test = pd.concat(X_test).reset_index(drop=True)\n",
    "y_test = pd.concat(y_test).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model on training data\\\n",
    "if retrain:\n",
    "    model_event = XGBClassifier(max_depth=4, n_estimators=200)\n",
    "    model_event.fit(X_train, y_train[\"nueccinc\"], sample_weight=y_train[\"train_weight\"])\n",
    "    dump(model_event, model_dir + \"model_event.pckl\")\n",
    "else:\n",
    "    model_event = load(model_dir + \"model_event.pckl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model_event.predict(X_test)\n",
    "target_names = [\"nueccinc\", \"background events\"]\n",
    "print(classification_report(y_test[\"nueccinc\"], y_pred, target_names=target_names))\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test[\"nueccinc\"], predictions)\n",
    "print(\"Test accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred_train = model_event.predict(X_train)\n",
    "predictions = [round(value) for value in y_pred_train]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_train[\"nueccinc\"], predictions)\n",
    "print(\"Train accuracy: %.2f%%\\n\" % (accuracy * 100.0))\n",
    "\n",
    "importances = model_event.feature_importances_\n",
    "sort = np.argsort(-importances)\n",
    "\n",
    "for i, (n, im) in enumerate(zip(np.array(col_train_event)[sort], importances[sort])):\n",
    "    print(\"%d. feature %s (%f)\" % (i + 1, n, im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(8, 4))\n",
    "\n",
    "y_pred = model_event.predict_proba(X_test).T[1]\n",
    "fpr, tpr, _ = roc_curve(y_test[\"nueccinc\"], y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "ax[0].hist(\n",
    "    y_pred[y_test[\"nueccinc\"] == 0],\n",
    "    alpha=0.5,\n",
    "    bins=50,\n",
    "    range=(0, 1),\n",
    "    label=r\"$\\nu_e$ CC Inclusive\",\n",
    "    density=False,\n",
    ")\n",
    "ax[0].hist(\n",
    "    y_pred[y_test[\"nueccinc\"] == 1],\n",
    "    alpha=0.5,\n",
    "    bins=50,\n",
    "    range=(0, 1),\n",
    "    label=\"background events\",\n",
    "    density=False,\n",
    ")\n",
    "ax[0].legend(loc=\"upper left\")\n",
    "ax[0].set_xlim(0, 1)\n",
    "ax[0].set_xlabel(\"Event identification\")\n",
    "ax[0].set_ylabel(\"Entries per bin\")\n",
    "ax[0].set_title(\"Event XGB\")\n",
    "\n",
    "ax[1].plot(fpr, tpr, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(output_dir + \"event_bdt_test.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# add the columns for each daughter (all samples)\n",
    "for k, v in sample_info.items():\n",
    "    v[\"daughters\"][\"score_event\"] = -1\n",
    "    mask_e_cand = v[\"daughters\"].eval(\"preselect & e_candidate\")\n",
    "    v[\"daughters\"].loc[mask_e_cand, \"score_event\"] = model_event.predict_proba(\n",
    "        v[\"daughters\"][col_train_event][mask_e_cand]\n",
    "    ).T[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_select = \"e_candidate & preselect & score_event>0.9898\"\n",
    "# Passing rate selection\n",
    "for k, v in sample_info.items():\n",
    "\n",
    "    v[\"daughters\"][\"select\"] = v[\"daughters\"].eval(query_select)\n",
    "    v[\"daughters\"][\"select\"] = v[\"daughters\"][\"select\"].groupby(\"event\").transform(max)\n",
    "\n",
    "    pass_rate = sum(v[\"daughters\"].eval(\"(e_candidate & select)\")) / v[\"numentries\"]\n",
    "    print(k, \"\\t{:.4f}%\".format(pass_rate * 100))\n",
    "\n",
    "# Passing rate signal, weights applied!\n",
    "pass_rate = sum(\n",
    "    sample_info[\"NUE\"][\"daughters\"].eval(\"(e_candidate & select)*weightSpline*nueccinc\")\n",
    ") / sum(sample_info[\"NUE\"][\"mc\"][\"weightSpline\"] * sample_info[\"NUE\"][\"nueccinc\"])\n",
    "print(\"Nue signal passing the selection \\t{:.2f}%\".format(pass_rate * 100))\n",
    "nue_pass = (\n",
    "    sum(\n",
    "        sample_info[\"NUE\"][\"daughters\"].eval(\n",
    "            \"(e_candidate & select)*weightSpline*nueccinc\"\n",
    "        )\n",
    "    )\n",
    "    * sample_info[\"NUE\"][\"scaling\"]\n",
    "    * pot_scale\n",
    ")\n",
    "print(\n",
    "    \"Nue Intrinsic signal passing: {0:0.3f} per {1:0.2g} POT\".format(\n",
    "        nue_pass, pot_target\n",
    "    )\n",
    ")\n",
    "lee_pass = (\n",
    "    sum(\n",
    "        sample_info[\"NUE\"][\"daughters\"].eval(\n",
    "            \"(e_candidate & select)*leeweight*nueccinc\"\n",
    "        )\n",
    "    )\n",
    "    * sample_info[\"NUE\"][\"scaling\"]\n",
    "    * pot_scale\n",
    ")\n",
    "print(\"Nue LEE signal passing: {0:0.3f} per {1:0.2g} POT\".format(lee_pass, pot_target))\n",
    "\n",
    "## Calculate the purity:\n",
    "purity_denom = (\n",
    "    sum(sample_info[\"MC\"][\"daughters\"].eval(\"(e_candidate & select)*weightSpline\"))\n",
    "    * sample_info[\"MC\"][\"scaling\"]\n",
    ")\n",
    "purity_denom += (\n",
    "    sum(sample_info[\"DRT\"][\"daughters\"].eval(\"(e_candidate & select)*weightSpline\"))\n",
    "    * sample_info[\"DRT\"][\"scaling\"]\n",
    ")\n",
    "purity_denom += (\n",
    "    sum(sample_info[\"Off\"][\"daughters\"].eval(\"(e_candidate & select)\"))\n",
    "    * sample_info[\"Off\"][\"scaling\"]\n",
    ")\n",
    "\n",
    "purity_mc = (\n",
    "    sum(\n",
    "        sample_info[\"NUE\"][\"daughters\"].eval(\n",
    "            \"(e_candidate & select)*weightSpline*nueccinc\"\n",
    "        )\n",
    "    )\n",
    "    * sample_info[\"NUE\"][\"scaling\"]\n",
    "    / purity_denom\n",
    ")\n",
    "purity_data = (\n",
    "    sum(\n",
    "        sample_info[\"NUE\"][\"daughters\"].eval(\n",
    "            \"(e_candidate & select)*weightSpline*nueccinc\"\n",
    "        )\n",
    "    )\n",
    "    * sample_info[\"NUE\"][\"scaling\"]\n",
    "    / sum(sample_info[\"On\"][\"daughters\"].eval(\"(e_candidate & select)\"))\n",
    ")\n",
    "print(\n",
    "    \"Purity MC: {:.1f}%\\nData/MC-ratio: {:.2f}\\n\".format(\n",
    "        purity_mc * 100,\n",
    "        sum(sample_info[\"On\"][\"daughters\"].eval(\"(e_candidate & select)\"))\n",
    "        / purity_denom,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\n",
    "    output_dir + \"events_run{}.txt\".format(run),\n",
    "    sample_info[\"On\"][\"daughters\"].query(\"(e_candidate & select)\")[\n",
    "        [\"run\", \"sub\", \"evt\"]\n",
    "    ],\n",
    "    fmt=\"%u\",\n",
    ")\n",
    "sample_info[\"On\"][\"daughters\"].query(\"(e_candidate & select)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pickle.dump(sample_info, open(input_dir+\"samples.pckl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(8, 4))\n",
    "\n",
    "ax[0].hist(\n",
    "    sample_info[\"NUE\"][\"daughters\"]\n",
    "    .query(\"nueccinc\")[\"true_vtx_distance\"]\n",
    "    .xs(0, level=\"daughter\"),\n",
    "    bins=50,\n",
    "    range=(0, 5),\n",
    "    label=\"|true_nu_vtx - reco_nu_vtx_sce|\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "ax[0].hist(\n",
    "    sample_info[\"NUE\"][\"daughters\"]\n",
    "    .query(\"nueccinc\")[\"true_vtx_distance_check\"]\n",
    "    .xs(0, level=\"daughter\"),\n",
    "    bins=50,\n",
    "    range=(0, 5),\n",
    "    label=\"|true_nu_vtx_sce - reco_nu_vtx|\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "ax[0].set_xlabel(\"Neutrino vertex distance [cm]\")\n",
    "ax[0].set_title(r\"$\\nu_e$ CC Inclusive\", loc=\"left\")\n",
    "ax[0].set_title(\"Run3 Overlay\", loc=\"right\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].hist(\n",
    "    sample_info[\"NUE\"][\"daughters\"]\n",
    "    .query(\"nueccinc\")\n",
    "    .xs(0, level=\"daughter\")\n",
    "    .eval(\"true_nu_vtx_x+@x_sce_magic-reco_nu_vtx_sce_x\"),\n",
    "    bins=51,\n",
    "    range=(-2, 2),\n",
    "    label=\"|true_nu_vtx - reco_nu_vtx_sce|\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "ax[1].hist(\n",
    "    sample_info[\"NUE\"][\"daughters\"]\n",
    "    .query(\"nueccinc\")\n",
    "    .xs(0, level=\"daughter\")\n",
    "    .eval(\"true_nu_vtx_sce_x-reco_nu_vtx_x\"),\n",
    "    bins=51,\n",
    "    range=(-2, 2),\n",
    "    label=\"|true_nu_vtx_sce - reco_nu_vtx|\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "ax[1].set_xlabel(\"Neutrino vertex distance x-coordinate [cm]\")\n",
    "ax[1].set_title(r\"$\\nu_e$ CC Inclusive\", loc=\"left\")\n",
    "ax[1].set_title(\"Run3 Overlay\", loc=\"right\")\n",
    "ax[1].set_ylim(0, ax[1].get_ylim()[1] * 1.25)\n",
    "ax[1].legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(output_dir + \"vtx_distance.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, figsize=(9, 4))\n",
    "\n",
    "data = sample_info[\"NUE\"][\"daughters\"].query(\"e_candidate & abs(backtracked_pdg==11)\")[\n",
    "    [\"shr_tkfit_dedx_y_v\", \"shr_tkfit_dedx_wm_v\"]\n",
    "]\n",
    "\n",
    "for col in data.columns:\n",
    "    ax.hist(data[col], bins=50, range=(0, 20), label=col, alpha=0.5)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(output_dir + \"e_preselection_dedx.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uproot env",
   "language": "python",
   "name": "uproot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
